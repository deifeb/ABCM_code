"""
ABCMä¸»ç³»ç»Ÿ - ABCM Main System

åŸºäºä»£ç†çš„åä½œæ¨¡å‹ä¸»ç³»ç»Ÿï¼Œåè°ƒä¸‰ä¸ªä»£ç†è¿›è¡Œé—´æ­‡æ€§éœ€æ±‚é¢„æµ‹
Agent-Based Collaborative Model main system that coordinates three agents 
for intermittent demand forecasting

ç³»ç»Ÿæ¶æ„ System Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    ç‰¹å¾    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    èšç±»æ ‡ç­¾    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä»£ç†1         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   ä»£ç†2         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€>   â”‚   ä»£ç†3         â”‚
â”‚ ç‰¹å¾æå–ä»£ç†     â”‚   Features â”‚ åˆ†ç±»ä»£ç†        â”‚  Cluster      â”‚ æ¨¡å‹é€‰æ‹©ä»£ç†     â”‚
â”‚ Feature         â”‚            â”‚ Classification  â”‚  Labels       â”‚ Model Selection â”‚
â”‚ Extraction      â”‚            â”‚ Agent          â”‚               â”‚ Agent          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†‘                              â†‘                              â†‘
       â”‚        åé¦ˆå¾ªç¯ Feedback Loop â”‚                              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¸»è¦åŠŸèƒ½ Main Functions:
- åè°ƒä¸‰ä¸ªä»£ç†çš„åä½œ Coordinate collaboration of three agents
- ç®¡ç†è¿­ä»£åé¦ˆè¿‡ç¨‹ Manage iterative feedback process
- æä¾›ç³»ç»Ÿçº§æ¥å£ Provide system-level interface
- å¤„ç†æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ Handle model training and prediction

ä½œè€… Author: ABCM Team
åˆ›å»ºæ—¶é—´ Created: 2024
"""

import warnings
import numpy as np
import pandas as pd
from typing import Dict, Any, Tuple, Optional
from scipy import stats

from agents import FeatureExtractionAgent, ClassificationAgent, ModelSelectionAgent
from models import ForecastingModels
from utils import FileUtils
from config import get_config, ABCMConfig

warnings.filterwarnings("ignore")


class ABCMSystem:
    """
    ABCMä¸»ç³»ç»Ÿç±»
    Main ABCM System class
    
    è¯¥ç±»æ˜¯æ•´ä¸ªABCMç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£åè°ƒä¸‰ä¸ªä»£ç†è¿›è¡Œåä½œå¼é—´æ­‡æ€§éœ€æ±‚é¢„æµ‹
    This class is the core of the entire ABCM system, responsible for coordinating 
    three agents for collaborative intermittent demand forecasting
    
    ç³»ç»Ÿç‰¹ç‚¹ System Features:
    1. ä»£ç†åä½œ - ä¸‰ä¸ªä¸“é—¨åŒ–ä»£ç†çš„æ™ºèƒ½åä½œ
       Agent Collaboration - Intelligent collaboration of three specialized agents
       
    2. è¿­ä»£ä¼˜åŒ– - é€šè¿‡åé¦ˆæœºåˆ¶ä¸æ–­æ”¹è¿›é¢„æµ‹æ€§èƒ½
       Iterative Optimization - Continuously improve prediction performance through feedback
       
    3. è‡ªé€‚åº”å­¦ä¹  - æ ¹æ®æ•°æ®ç‰¹æ€§è‡ªåŠ¨è°ƒæ•´ç­–ç•¥
       Adaptive Learning - Automatically adjust strategies based on data characteristics
       
    4. æ¨¡å—åŒ–è®¾è®¡ - æ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹ä½¿ç”¨å’Œæ‰©å±•
       Modular Design - Each component can be used and extended independently
       
    5. æ™ºèƒ½æ•°æ®é¢„å¤„ç† - åŸºäºä¿®æ­£z-scoreçš„è‡ªé€‚åº”å¼‚å¸¸å€¼å¤„ç†
       Intelligent Data Preprocessing - Adaptive outlier handling based on modified z-score
    """
    
    def __init__(self, config: Optional[ABCMConfig] = None, pretrained_metalearner_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ABCMç³»ç»Ÿ
        Initialize the ABCM system
        
        å‚æ•° Args:
            config (ABCMConfig): é…ç½®å¯¹è±¡ Configuration object
            pretrained_metalearner_path (str): é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è·¯å¾„ Path to pretrained meta-learner from Cross-validation training
        """
        self.config = config or get_config()
        
        print("åˆå§‹åŒ–ABCMç³»ç»Ÿ... Initializing ABCM system...")
        
        # åˆå§‹åŒ–ä¸‰ä¸ªä»£ç† Initialize three agents
        self.agent1 = FeatureExtractionAgent(
            encoding_dim=self.config.feature_extraction.encoding_dim,
            autoencoder_epochs=self.config.feature_extraction.autoencoder_epochs,
            batch_size=self.config.feature_extraction.batch_size
        )
        print("ä»£ç†1(ç‰¹å¾æå–ä»£ç†)åˆå§‹åŒ–å®Œæˆ Agent 1 (Feature Extraction) initialized")
        
        self.agent2 = ClassificationAgent(
            accuracy_threshold=self.config.classification.accuracy_threshold,
            max_clusters=self.config.classification.max_clusters
        )
        print("ä»£ç†2(åˆ†ç±»ä»£ç†)åˆå§‹åŒ–å®Œæˆ Agent 2 (Classification) initialized")
        
        # åˆå§‹åŒ–ä»£ç†3ï¼Œæ”¯æŒé¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Initialize Agent 3 with pretrained meta-learner support
        self.agent3 = ModelSelectionAgent(
            error_threshold=self.config.model_selection.error_threshold,
            models_list=self.config.system.candidate_models,
            pretrained_metalearner_path=pretrained_metalearner_path
        )
        print("ä»£ç†3(æ¨¡å‹é€‰æ‹©ä»£ç†)åˆå§‹åŒ–å®Œæˆ Agent 3 (Model Selection) initialized")
        
        # åˆå§‹åŒ–é¢„æµ‹æ¨¡å‹å®¹å™¨ Initialize forecasting models container
        self.forecasting_models = ForecastingModels(
            prediction_length=self.config.forecasting.prediction_length,
            freq=self.config.forecasting.freq
        )
        print("é¢„æµ‹æ¨¡å‹å®¹å™¨åˆå§‹åŒ–å®Œæˆ Forecasting models container initialized")
        
        # ç³»ç»ŸçŠ¶æ€å˜é‡ System state variables
        self.features = None
        self.cluster_labels = None
        self.model_errors = None
        self.best_models = None
        self.iteration_count = 0
        self.converged = False
        
        # æ•°æ®é¢„å¤„ç†çŠ¶æ€ Data preprocessing state
        self.outlier_info = {}  # å­˜å‚¨å¼‚å¸¸å€¼å¤„ç†ä¿¡æ¯
        self.preprocessed_data = None  # å­˜å‚¨é¢„å¤„ç†åçš„æ•°æ®
        
        # å­˜å‚¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è·¯å¾„ä¿¡æ¯ Store pretrained meta-learner path info
        self.pretrained_metalearner_path = pretrained_metalearner_path
        
        print("ABCMç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ ABCM system initialization completed!")
        if pretrained_metalearner_path and self.agent3.use_pretrained:
            print(f"ğŸ¯ ç³»ç»Ÿå°†ä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è¿›è¡Œæ¨¡å‹é€‰æ‹© System will use pretrained meta-learner for model selection")
        else:
            print(f"âš™ï¸  ç³»ç»Ÿå°†ä½¿ç”¨å®æ—¶å…ƒå­¦ä¹ è¿›è¡Œæ¨¡å‹é€‰æ‹© System will use real-time meta-learning for model selection")
    
    def calculate_adaptive_threshold(self, non_zero_data: np.ndarray) -> float:
        """
        è®¡ç®—è‡ªé€‚åº”z-scoreé˜ˆå€¼
        Calculate adaptive z-score threshold
        
        åŸºäºéé›¶éœ€æ±‚å˜å¼‚ç³»æ•°å¹³æ–¹ä¸ä¸´ç•Œå€¼0.49çš„å…³ç³»æ¥åŠ¨æ€ç¡®å®šz-scoreé˜ˆå€¼
        The Z-score threshold is dynamically determined according to the squared coefficient of variation 
        of non-zero demand observations and its relationship with the critical value of 0.49
        
        å‚æ•° Args:
            non_zero_data (np.ndarray): éé›¶éœ€æ±‚æ•°æ® Non-zero demand data
            
        è¿”å› Returns:
            float: è‡ªé€‚åº”é˜ˆå€¼ Adaptive threshold
        """
        if len(non_zero_data) == 0:
            return 2.5  # é»˜è®¤é˜ˆå€¼ Default threshold
        
        # è®¡ç®—å˜å¼‚ç³»æ•° Calculate coefficient of variation
        mean_val = np.mean(non_zero_data)
        std_val = np.std(non_zero_data)
        
        if mean_val == 0:
            return 2.5  # é»˜è®¤é˜ˆå€¼ Default threshold
        
        cv = std_val / mean_val  # å˜å¼‚ç³»æ•° Coefficient of variation
        cv_squared = cv ** 2  # å˜å¼‚ç³»æ•°å¹³æ–¹ Squared coefficient of variation
        
        # åŸºäºä¸ä¸´ç•Œå€¼0.49çš„å…³ç³»è®¡ç®—é˜ˆå€¼
        # Calculate threshold based on relationship with critical value of 0.49
        critical_value = 0.49
        
        if cv_squared <= critical_value:
            # ä½å˜å¼‚æ€§æ•°æ®ï¼Œä½¿ç”¨è¾ƒä½é˜ˆå€¼(æ›´ä¸¥æ ¼çš„å¼‚å¸¸å€¼æ£€æµ‹)
            # Low variability data, use lower threshold (stricter outlier detection)
            threshold = 2.0 + (cv_squared / critical_value) * 0.5  # 2.0 to 2.5
        else:
            # é«˜å˜å¼‚æ€§æ•°æ®ï¼Œä½¿ç”¨è¾ƒé«˜é˜ˆå€¼(æ›´å®½æ¾çš„å¼‚å¸¸å€¼æ£€æµ‹)
            # High variability data, use higher threshold (more lenient outlier detection)
            excess_ratio = cv_squared / critical_value
            threshold = 2.5 + min(excess_ratio - 1, 1.0) * 1.0  # 2.5 to 3.5
        
        return threshold
    
    def detect_outliers_modified_zscore(self, data: pd.Series, strategy: str = 'strategy1') -> Tuple[np.ndarray, Dict]:
        """
        ä½¿ç”¨ä¿®æ­£z-scoreæ£€æµ‹å¼‚å¸¸å€¼
        Detect outliers using modified z-score
        
        å‚æ•° Args:
            data (pd.Series): æ—¶é—´åºåˆ—æ•°æ® Time series data
            strategy (str): å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy
                          'strategy1': ä½¿ç”¨éé›¶éœ€æ±‚çš„MADå’Œæ ‡å‡†å·®ï¼Œä¸­ä½æ•°æ›¿æ¢
                          'strategy2': ä½¿ç”¨éé›¶éœ€æ±‚å‡å€¼ï¼Œå…¶ä»–åŒstrategy1
                          'strategy3': ä¸åšå¼‚å¸¸å€¼å¤„ç†
                          
        è¿”å› Returns:
            tuple: (outlier_mask, info_dict) å¼‚å¸¸å€¼æ©ç å’Œä¿¡æ¯å­—å…¸
        """
        info_dict = {
            'strategy': strategy,
            'total_observations': len(data),
            'zero_observations': (data == 0).sum(),
            'non_zero_observations': (data > 0).sum(),
            'outliers_detected': 0,
            'outliers_replaced': 0,
            'threshold_used': None,
            'cv_squared': None
        }
        
        if strategy == 'strategy3':
            # ç­–ç•¥3ï¼šä¸åšå¤„ç† Strategy 3: No processing
            return np.zeros(len(data), dtype=bool), info_dict
        
        # æå–éé›¶éœ€æ±‚æ•°æ® Extract non-zero demand data
        non_zero_mask = data > 0
        non_zero_data = data[non_zero_mask].values
        
        if len(non_zero_data) == 0:
            # æ²¡æœ‰éé›¶æ•°æ®ï¼Œæ— éœ€å¤„ç† No non-zero data, no processing needed
            return np.zeros(len(data), dtype=bool), info_dict
        
        # è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ Calculate adaptive threshold
        threshold = self.calculate_adaptive_threshold(non_zero_data)
        info_dict['threshold_used'] = threshold
        
        # è®¡ç®—å˜å¼‚ç³»æ•°å¹³æ–¹ç”¨äºè®°å½• Calculate squared CV for recording
        if np.mean(non_zero_data) > 0:
            cv_squared = (np.std(non_zero_data) / np.mean(non_zero_data)) ** 2
            info_dict['cv_squared'] = cv_squared
        
        # æ ¹æ®ç­–ç•¥è®¡ç®—å‚æ•° Calculate parameters based on strategy
        if strategy == 'strategy1':
            # ç­–ç•¥1ï¼šä½¿ç”¨MADä½œä¸ºæ›¿ä»£å‡å€¼ï¼Œéé›¶éœ€æ±‚æ ‡å‡†å·®ï¼Œä¸­ä½æ•°æ›¿æ¢
            # Strategy 1: Use MAD as substitute mean, non-zero std, median replacement
            mad = np.median(np.abs(non_zero_data - np.median(non_zero_data)))  # MAD
            substitute_mean = mad
            substitute_std = np.std(non_zero_data)
            replacement_value = np.median(non_zero_data)
            
        elif strategy == 'strategy2':
            # ç­–ç•¥2ï¼šä½¿ç”¨éé›¶éœ€æ±‚å‡å€¼ï¼Œå…¶ä»–åŒstrategy1
            # Strategy 2: Use non-zero mean, others same as strategy1
            mad = np.median(np.abs(non_zero_data - np.median(non_zero_data)))  # MAD
            substitute_mean = np.mean(non_zero_data)
            substitute_std = np.std(non_zero_data)
            replacement_value = np.median(non_zero_data)
        
        else:
            raise ValueError(f"æœªçŸ¥çš„å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥: {strategy}")
        
        # è®¡ç®—ä¿®æ­£z-score (ä»…å¯¹éé›¶æ•°æ®) Calculate modified z-score (only for non-zero data)
        if substitute_std == 0:
            # æ ‡å‡†å·®ä¸º0ï¼Œæ— æ³•è®¡ç®—z-score Standard deviation is 0, cannot calculate z-score
            outlier_mask = np.zeros(len(data), dtype=bool)
        else:
            # åˆå§‹åŒ–å¼‚å¸¸å€¼æ©ç  Initialize outlier mask
            outlier_mask = np.zeros(len(data), dtype=bool)
            
            # ä»…å¯¹éé›¶æ•°æ®è®¡ç®—z-score Calculate z-score only for non-zero data
            z_scores = np.abs(non_zero_data - substitute_mean) / substitute_std
            non_zero_outliers = z_scores > threshold
            
            # å°†éé›¶æ•°æ®çš„å¼‚å¸¸å€¼æ˜ å°„å›åŸå§‹æ•°æ® Map non-zero outliers back to original data
            non_zero_indices = np.where(non_zero_mask)[0]
            outlier_mask[non_zero_indices[non_zero_outliers]] = True
        
        info_dict['outliers_detected'] = np.sum(outlier_mask)
        
        return outlier_mask, info_dict
    
    def handle_outliers(self, data: pd.DataFrame, strategy: str = 'strategy1') -> Tuple[pd.DataFrame, Dict]:
        """
        å¤„ç†æ•´ä¸ªæ•°æ®é›†çš„å¼‚å¸¸å€¼
        Handle outliers for the entire dataset
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            strategy (str): å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy
                          'strategy1': MAD + ä¸­ä½æ•°æ›¿æ¢
                          'strategy2': å‡å€¼ + ä¸­ä½æ•°æ›¿æ¢  
                          'strategy3': ä¸å¤„ç†
                          
        è¿”å› Returns:
            tuple: (processed_data, processing_info) å¤„ç†åçš„æ•°æ®å’Œå¤„ç†ä¿¡æ¯
        """
        print("\n" + "=" * 70)
        print("ğŸ”§ æ•°æ®é¢„å¤„ç†ï¼šå¼‚å¸¸å€¼å¤„ç† DATA PREPROCESSING: OUTLIER HANDLING")
        print("=" * 70)
        print(f"ä½¿ç”¨ç­–ç•¥ Using strategy: {strategy}")
        
        if strategy == 'strategy3':
            print("ç­–ç•¥3ï¼šä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç† Strategy 3: No outlier processing")
            processing_info = {
                'strategy': strategy,
                'total_spare_parts': data.shape[1],
                'total_outliers_detected': 0,
                'total_outliers_replaced': 0,
                'spare_parts_info': {}
            }
            return data.copy(), processing_info
        
        processed_data = data.copy()
        processing_info = {
            'strategy': strategy,
            'total_spare_parts': data.shape[1],
            'total_outliers_detected': 0,
            'total_outliers_replaced': 0,
            'spare_parts_info': {}
        }
        
        print(f"å¤„ç† {data.shape[1]} ä¸ªå¤‡ä»¶çš„æ—¶é—´åºåˆ—æ•°æ®...")
        print(f"Processing time series data for {data.shape[1]} spare parts...")
        
        outliers_by_part = []
        
        # é€ä¸ªå¤‡ä»¶å¤„ç† Process each spare part individually
        for col in data.columns:
            series = data[col]
            
            # æ£€æµ‹å¼‚å¸¸å€¼ Detect outliers
            outlier_mask, part_info = self.detect_outliers_modified_zscore(series, strategy)
            
            if np.any(outlier_mask):
                # è®¡ç®—æ›¿æ¢å€¼(ä¸­ä½æ•°) Calculate replacement value (median)
                non_zero_data = series[series > 0]
                if len(non_zero_data) > 0:
                    replacement_value = np.median(non_zero_data)
                    
                    # æ›¿æ¢å¼‚å¸¸å€¼ Replace outliers
                    processed_data.loc[outlier_mask, col] = replacement_value
                    part_info['outliers_replaced'] = np.sum(outlier_mask)
                    part_info['replacement_value'] = replacement_value
                else:
                    part_info['outliers_replaced'] = 0
                    part_info['replacement_value'] = None
            
            # å­˜å‚¨å¤‡ä»¶ä¿¡æ¯ Store spare part info
            processing_info['spare_parts_info'][col] = part_info
            processing_info['total_outliers_detected'] += part_info['outliers_detected']
            processing_info['total_outliers_replaced'] += part_info['outliers_replaced']
            
            outliers_by_part.append(part_info['outliers_detected'])
        
        # æ‰“å°å¤„ç†ç»“æœæ‘˜è¦ Print processing summary
        print(f"\nğŸ“Š å¼‚å¸¸å€¼å¤„ç†æ‘˜è¦ Outlier Processing Summary:")
        print(f"æ€»å¼‚å¸¸å€¼æ£€æµ‹æ•° Total outliers detected: {processing_info['total_outliers_detected']}")
        print(f"æ€»å¼‚å¸¸å€¼æ›¿æ¢æ•° Total outliers replaced: {processing_info['total_outliers_replaced']}")
        print(f"å¼‚å¸¸å€¼æ¯”ä¾‹ Outlier ratio: {processing_info['total_outliers_detected']/(data.shape[0]*data.shape[1])*100:.2f}%")
        
        if processing_info['total_outliers_detected'] > 0:
            print(f"æ¯ä¸ªå¤‡ä»¶å¹³å‡å¼‚å¸¸å€¼æ•° Average outliers per spare part: {np.mean(outliers_by_part):.1f}")
            print(f"å¼‚å¸¸å€¼æ•°é‡åˆ†å¸ƒ Outlier count distribution:")
            print(f"  æœ€å°å€¼ Min: {np.min(outliers_by_part)}")
            print(f"  æœ€å¤§å€¼ Max: {np.max(outliers_by_part)}")
            print(f"  ä¸­ä½æ•° Median: {np.median(outliers_by_part):.1f}")
        
        # æ•°æ®å˜åŒ–ç»Ÿè®¡ Data change statistics  
        original_sum = data.sum().sum()
        processed_sum = processed_data.sum().sum()
        change_ratio = (processed_sum - original_sum) / original_sum * 100 if original_sum > 0 else 0
        
        print(f"\nğŸ“ˆ æ•°æ®å˜åŒ–ç»Ÿè®¡ Data Change Statistics:")
        print(f"åŸå§‹æ€»éœ€æ±‚ Original total demand: {original_sum:.0f}")
        print(f"å¤„ç†åæ€»éœ€æ±‚ Processed total demand: {processed_sum:.0f}")
        print(f"éœ€æ±‚å˜åŒ–æ¯”ä¾‹ Demand change ratio: {change_ratio:+.2f}%")
        
        return processed_data, processing_info
    
    def extract_features(self, data: pd.DataFrame, strategy: str = 'combined') -> pd.DataFrame:
        """
        æ­¥éª¤1ï¼šç‰¹å¾æå–
        Step 1: Feature extraction
        
        ä½¿ç”¨ä»£ç†1ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æå–ç‰¹å¾
        Use Agent 1 to extract features from time series data
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            strategy (str): ç‰¹å¾æå–ç­–ç•¥ Feature extraction strategy
            
        è¿”å› Returns:
            pd.DataFrame: æå–çš„ç‰¹å¾ Extracted features
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤1ï¼šç‰¹å¾æå– STEP 1: FEATURE EXTRACTION")
        print("=" * 60)
        
        self.features = self.agent1.extract_features(data, strategy)
        
        print(f"æˆåŠŸæå–{self.features.shape[1]}ä¸ªç‰¹å¾ï¼Œæ¥è‡ª{self.features.shape[0]}ä¸ªæ—¶é—´åºåˆ—")
        print(f"Successfully extracted {self.features.shape[1]} features from {self.features.shape[0]} time series")
        print(f"ä½¿ç”¨ç­–ç•¥ Used strategy: {strategy}")
        
        return self.features
    
    def classify_spare_parts(self, features: Optional[pd.DataFrame] = None) -> Tuple[np.array, Dict]:
        """
        æ­¥éª¤2ï¼šå¤‡ä»¶åˆ†ç±»
        Step 2: Spare parts classification
        
        ä½¿ç”¨ä»£ç†2æ ¹æ®éœ€æ±‚æ¨¡å¼å¯¹å¤‡ä»¶è¿›è¡Œåˆ†ç±»
        Use Agent 2 to classify spare parts based on demand patterns
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            
        è¿”å› Returns:
            tuple: (cluster_labels, evaluation_results) èšç±»æ ‡ç­¾å’Œè¯„ä¼°ç»“æœ
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤2ï¼šå¤‡ä»¶åˆ†ç±» STEP 2: SPARE PARTS CLASSIFICATION")
        print("=" * 60)
        
        if features is None:
            features = self.features
            
        if features is None:
            raise ValueError("æ²¡æœ‰å¯ç”¨ç‰¹å¾ã€‚è¯·å…ˆè¿è¡Œextract_features()æ–¹æ³•ã€‚No features available. Run extract_features() first.")
        
        self.cluster_labels, evaluation = self.agent2.classify(
            features,
            use_pca=self.config.classification.use_pca,
            use_cosine_similarity=self.config.classification.use_cosine_similarity
        )
        
        n_clusters = len(np.unique(self.cluster_labels))
        print(f"åˆ†ç±»å®Œæˆï¼Œå…±ç”Ÿæˆ{n_clusters}ä¸ªèšç±»")
        print(f"Classification completed with {n_clusters} clusters")
        print(f"èšç±»å‡†ç¡®åº¦ Clustering accuracy: {evaluation['accuracy']:.3f}")
        
        return self.cluster_labels, evaluation
    
    def run_forecasting_models(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        æ­¥éª¤3ï¼šè¿è¡Œå€™é€‰é¢„æµ‹æ¨¡å‹
        Step 3: Run candidate forecasting models
        
        è¿è¡Œæ‰€æœ‰å€™é€‰é¢„æµ‹æ¨¡å‹ä»¥è·å–é”™è¯¯æŒ‡æ ‡
        Run all candidate forecasting models to get error metrics
        
        å‚æ•° Args:
            data (pd.DataFrame): åŸå§‹æ—¶é—´åºåˆ—æ•°æ® Original time series data
            
        è¿”å› Returns:
            dict: æ‰€æœ‰é¢„æµ‹æ¨¡å‹çš„ç»“æœ Results from all forecasting models
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤3ï¼šè¿è¡Œå€™é€‰é¢„æµ‹æ¨¡å‹ STEP 3: RUN CANDIDATE FORECASTING MODELS")
        print("=" * 60)
        
        results = self.forecasting_models.run_all_models(
            data, self.config.system.candidate_models
        )
        
        # æå–é”™è¯¯æŒ‡æ ‡ Extract error metrics
        error_dict = {}
        successful_models = 0
        
        for model_name, result in results.items():
            if result['metrics'] is not None:
                # ä½¿ç”¨MASEä½œä¸ºä¸»è¦æŒ‡æ ‡ï¼Œå¤‡é€‰MAE Use MASE as primary metric, fallback to MAE
                if isinstance(result['metrics'], dict):
                    # å•ä¸ªæŒ‡æ ‡å€¼ Single metric value
                    error = result['metrics'].get('MASE', result['metrics'].get('MAE', 1.0))
                    error_dict[model_name] = [error] * len(data.columns)
                elif isinstance(result['metrics'], (list, np.ndarray)):
                    # æ¯ä¸ªå¤‡ä»¶çš„æŒ‡æ ‡å€¼ Per spare part metric values
                    error_dict[model_name] = result['metrics']
                else:
                    # æ ‡é‡å€¼ Scalar value
                    error_dict[model_name] = [float(result['metrics'])] * len(data.columns)
                successful_models += 1
        
        # åˆ›å»ºé”™è¯¯æ•°æ®æ¡† Create error DataFrame
        if error_dict:
            self.model_errors = pd.DataFrame(error_dict)
        else:
            # ä½¿ç”¨è™šæ‹Ÿæ•°æ®ä½œä¸ºå›é€€ Fallback with dummy data
            print("è­¦å‘Šï¼šæ²¡æœ‰æˆåŠŸçš„æ¨¡å‹ç»“æœï¼Œä½¿ç”¨è™šæ‹Ÿæ•°æ® Warning: No successful model results, using dummy data")
            self.model_errors = pd.DataFrame({
                model: np.random.uniform(0.1, 2.0, len(data.columns))
                for model in self.config.system.candidate_models
            })
        
        print(f"é¢„æµ‹æ¨¡å‹è¿è¡Œå®Œæˆï¼š{successful_models}/{len(results)}ä¸ªæ¨¡å‹æˆåŠŸ")
        print(f"Forecasting completed: {successful_models}/{len(results)} models successful")
        
        return results
    
    def select_best_models(self, features: Optional[pd.DataFrame] = None,
                          cluster_labels: Optional[np.array] = None,
                          model_errors: Optional[pd.DataFrame] = None) -> np.array:
        """
        æ­¥éª¤4ï¼šæ™ºèƒ½æ¨¡å‹é€‰æ‹©
        Step 4: Intelligent model selection
        
        ä½¿ç”¨ä»£ç†3ä¸ºæ¯ä¸ªå¤‡ä»¶é€‰æ‹©æœ€ä½³é¢„æµ‹æ¨¡å‹
        Use Agent 3 to select the best forecasting model for each spare part
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            cluster_labels (np.array): æ¥è‡ªä»£ç†2çš„èšç±»æ ‡ç­¾ Cluster labels from Agent 2
            model_errors (pd.DataFrame): é¢„æµ‹æ¨¡å‹çš„é”™è¯¯ Forecasting model errors
            
        è¿”å› Returns:
            np.array: æœ€ä½³æ¨¡å‹æ¨è Best model recommendations
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤4ï¼šæ™ºèƒ½æ¨¡å‹é€‰æ‹© STEP 4: INTELLIGENT MODEL SELECTION")
        print("=" * 60)
        
        if features is None:
            features = self.features
        if cluster_labels is None:
            cluster_labels = self.cluster_labels
        if model_errors is None:
            model_errors = self.model_errors
            
        if any(x is None for x in [features, cluster_labels, model_errors]):
            raise ValueError("ç¼ºå°‘å¿…éœ€æ•°æ®ã€‚è¯·å…ˆè¿è¡Œå‰é¢çš„æ­¥éª¤ã€‚Missing required data. Run previous steps first.")
        
        # å‡†å¤‡å…ƒå­¦ä¹ æ•°æ® Prepare meta-learning data
        X_meta, y_meta = self.agent3.prepare_meta_learning_data(
            features, model_errors, cluster_labels
        )
        
        # è®­ç»ƒå…ƒå­¦ä¹ å™¨ Train meta-learner
        training_results = self.agent3.train_meta_learner(
            X_meta, y_meta,
            use_lightgbm=self.config.model_selection.use_lightgbm
        )
        
        # è·å–æ¨¡å‹æ¨è Get model recommendations
        self.best_models = self.agent3.predict_best_models(features, cluster_labels)
        
        print(f"æ¨¡å‹é€‰æ‹©å®Œæˆï¼Œå…ƒå­¦ä¹ å™¨å‡†ç¡®åº¦: {training_results['accuracy']:.3f}")
        print(f"Model selection completed with meta-learner accuracy: {training_results['accuracy']:.3f}")
        print(f"æ¨èæ¨¡å‹åˆ†å¸ƒ Recommended model distribution:")
        
        from collections import Counter
        model_counts = Counter(self.best_models)
        for model, count in model_counts.items():
            print(f"  {model}: {count}ä¸ªå¤‡ä»¶ spare parts")
        
        return self.best_models
    
    def evaluate_and_provide_feedback(self) -> Dict[str, Any]:
        """
        æ­¥éª¤5ï¼šç³»ç»Ÿè¯„ä¼°å’Œåé¦ˆ
        Step 5: System evaluation and feedback
        
        è¯„ä¼°ç³»ç»Ÿæ€§èƒ½å¹¶åœ¨ä»£ç†é—´æä¾›åé¦ˆ
        Evaluate system performance and provide feedback between agents
        
        è¿”å› Returns:
            dict: è¯„ä¼°ç»“æœå’Œåé¦ˆä¿¡å· Evaluation results and feedback signals
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤5ï¼šç³»ç»Ÿè¯„ä¼°å’Œåé¦ˆ STEP 5: SYSTEM EVALUATION AND FEEDBACK")
        print("=" * 60)
        
        # ä»£ç†2è¯„ä¼° Agent 2 evaluation
        agent2_evaluation = self.agent2.evaluate_clustering_quality()
        agent2_feedback = self.agent2.provide_feedback_to_agent1(agent2_evaluation)
        
        # ä»£ç†3è¯„ä¼° Agent 3 evaluation
        agent3_evaluation = self.agent3.evaluate_error_threshold(
            self.model_errors, self.best_models, self.cluster_labels
        )
        agent3_feedback = self.agent3.provide_feedback_to_agent1(agent3_evaluation)
        
        # å‘ä»£ç†1æä¾›åé¦ˆ Provide feedback to Agent 1
        if self.config.feedback_enabled:
            if not agent2_evaluation['meets_threshold']:
                print("ä»£ç†2åé¦ˆï¼šèšç±»å‡†ç¡®åº¦ä½äºé˜ˆå€¼ Agent 2 feedback: Clustering accuracy below threshold")
                self.agent1.update_strategy(agent2_feedback)
            
            if agent3_evaluation['exceeds_threshold']:
                print("ä»£ç†3åé¦ˆï¼šé¢„æµ‹é”™è¯¯è¶…è¿‡é˜ˆå€¼ Agent 3 feedback: Forecasting error exceeds threshold")
                self.agent1.update_strategy(agent3_feedback)
        
        evaluation_results = {
            'agent2_evaluation': agent2_evaluation,
            'agent2_feedback': agent2_feedback,
            'agent3_evaluation': agent3_evaluation,
            'agent3_feedback': agent3_feedback,
            'iteration': self.iteration_count
        }
        
        # æ£€æŸ¥æ”¶æ•›æ€§ Check convergence
        if (agent2_evaluation['meets_threshold'] and 
            not agent3_evaluation['exceeds_threshold']):
            self.converged = True
            print("ğŸ‰ ç³»ç»Ÿå·²æ”¶æ•›ï¼ System has converged!")
        else:
            print("ç³»ç»Ÿå°šæœªæ”¶æ•›ï¼Œå°†ç»§ç»­è¿­ä»£ System not converged, will continue iteration")
        
        return evaluation_results
    
    def train(self, data: pd.DataFrame, max_iterations: Optional[int] = None, 
              outlier_strategy: str = 'strategy1') -> Dict[str, Any]:
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        Complete training workflow
        
        ä½¿ç”¨è¿­ä»£åé¦ˆè®­ç»ƒå®Œæ•´çš„ABCMç³»ç»Ÿ
        Train the complete ABCM system with iterative feedback
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•° Maximum number of iterations
            outlier_strategy (str): å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy
                                  'strategy1': ä½¿ç”¨MADå’Œæ ‡å‡†å·®ï¼Œä¸­ä½æ•°æ›¿æ¢
                                  'strategy2': ä½¿ç”¨éé›¶å‡å€¼ï¼Œå…¶ä»–åŒstrategy1  
                                  'strategy3': ä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†
            
        è¿”å› Returns:
            dict: å®Œæ•´çš„è®­ç»ƒç»“æœ Complete training results
        """
        if max_iterations is None:
            max_iterations = self.config.max_iterations
        
        # è¾“å…¥æ•°æ®æ ¡éªŒ Input data validation
        if not isinstance(data, pd.DataFrame):
            raise ValueError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯pandas DataFrame Input data must be pandas DataFrame")
        if data.empty:
            raise ValueError("è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©º Input data cannot be empty")
        if data.shape[0] < 10:
            raise ValueError("æ—¶é—´åºåˆ—é•¿åº¦å¤ªçŸ­ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ—¶æœŸ Time series too short, need at least 10 periods")
        if data.shape[1] < 5:
            raise ValueError("å¤‡ä»¶æ•°é‡å¤ªå°‘ï¼Œè‡³å°‘éœ€è¦5ä¸ªå¤‡ä»¶ Too few spare parts, need at least 5 spare parts")
        
        # éªŒè¯å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Validate outlier strategy
        valid_strategies = ['strategy1', 'strategy2', 'strategy3']
        if outlier_strategy not in valid_strategies:
            raise ValueError(f"æ— æ•ˆçš„å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥: {outlier_strategy}. æœ‰æ•ˆé€‰é¡¹: {valid_strategies}")
        
        print("=" * 80)
        print("ğŸš€ å¼€å§‹ABCMç³»ç»Ÿè®­ç»ƒ STARTING ABCM SYSTEM TRAINING")
        print("=" * 80)
        print(f"æ•°æ®è§„æ¨¡ Data size: {data.shape[1]}ä¸ªå¤‡ä»¶ spare parts, {data.shape[0]}ä¸ªæ—¶æœŸ periods")
        print(f"æœ€å¤§è¿­ä»£æ¬¡æ•° Maximum iterations: {max_iterations}")
        print(f"å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy: {outlier_strategy}")
        print(f"æ•°æ®æ ¡éªŒé€šè¿‡ âœ… Data validation passed")
        
        # ğŸ”§ æ­¥éª¤0ï¼šæ•°æ®é¢„å¤„ç† Step 0: Data preprocessing
        print("\n" + "=" * 80)
        print("ğŸ”§ æ­¥éª¤0ï¼šæ•°æ®é¢„å¤„ç† STEP 0: DATA PREPROCESSING")
        print("=" * 80)
        
        try:
            # æ‰§è¡Œå¼‚å¸¸å€¼å¤„ç† Perform outlier handling
            processed_data, self.outlier_info = self.handle_outliers(data, strategy=outlier_strategy)
            self.preprocessed_data = processed_data
            
            print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ Data preprocessing completed")
            print(f"ä½¿ç”¨æ•°æ® Using data: {'åŸå§‹æ•°æ®' if outlier_strategy == 'strategy3' else 'é¢„å¤„ç†åæ•°æ®'}")
            print(f"Using data: {'Original data' if outlier_strategy == 'strategy3' else 'Preprocessed data'}")
            
        except Exception as e:
            print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            print(f"âŒ Data preprocessing failed: {e}")
            print("å›é€€åˆ°åŸå§‹æ•°æ® Falling back to original data")
            processed_data = data.copy()
            self.outlier_info = {'error': str(e)}
            self.preprocessed_data = processed_data
        
        all_results = []
        training_errors = []  # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„é”™è¯¯ Record errors during training
        
        for iteration in range(max_iterations):
            self.iteration_count = iteration + 1
            print(f"\n{'ğŸ”„' * 20}")
            print(f"è¿­ä»£ ITERATION {self.iteration_count}/{max_iterations}")
            print(f"{'ğŸ”„' * 20}")
            
            try:
                # æ­¥éª¤1ï¼šç‰¹å¾æå– Step 1: Feature extraction
                print("\nğŸ“Š æ­¥éª¤1ï¼šç‰¹å¾æå– Step 1: Feature extraction")
                features = self.extract_features(processed_data)
                
                # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ Data consistency check
                if features.shape[0] != processed_data.shape[1]:
                    raise ValueError(f"ç‰¹å¾æ•°é‡({features.shape[0]})ä¸å¤‡ä»¶æ•°é‡({processed_data.shape[1]})ä¸åŒ¹é…")
                
                # æ­¥éª¤2ï¼šåˆ†ç±» Step 2: Classification
                print("\nğŸ¯ æ­¥éª¤2ï¼šå¤‡ä»¶åˆ†ç±» Step 2: Spare parts classification")
                cluster_labels, classification_eval = self.classify_spare_parts(features)
                
                # éªŒè¯èšç±»ç»“æœ Validate clustering results
                if len(cluster_labels) != features.shape[0]:
                    raise ValueError(f"èšç±»æ ‡ç­¾æ•°é‡({len(cluster_labels)})ä¸ç‰¹å¾æ•°é‡({features.shape[0]})ä¸åŒ¹é…")
                
                # æ­¥éª¤3ï¼šè¿è¡Œé¢„æµ‹æ¨¡å‹(ä»…åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£) Step 3: Run forecasting models (only in first iteration)
                if iteration == 0:
                    print("\nğŸ”® æ­¥éª¤3ï¼šè¿è¡Œé¢„æµ‹æ¨¡å‹ Step 3: Run forecasting models")
                    forecasting_results = self.run_forecasting_models(processed_data)
                    
                    # éªŒè¯é¢„æµ‹ç»“æœ Validate forecasting results
                    if self.model_errors is None or self.model_errors.empty:
                        raise ValueError("é¢„æµ‹æ¨¡å‹è¿è¡Œå¤±è´¥ï¼Œæœªè·å¾—é”™è¯¯æ•°æ®")
                    if len(self.model_errors) != processed_data.shape[1]:
                        raise ValueError(f"æ¨¡å‹é”™è¯¯æ•°é‡({len(self.model_errors)})ä¸å¤‡ä»¶æ•°é‡({processed_data.shape[1]})ä¸åŒ¹é…")
                
                # æ­¥éª¤4ï¼šæ¨¡å‹é€‰æ‹© Step 4: Model selection
                print("\nğŸ¤– æ­¥éª¤4ï¼šæ™ºèƒ½æ¨¡å‹é€‰æ‹© Step 4: Intelligent model selection")
                best_models = self.select_best_models(features, cluster_labels, self.model_errors)
                
                # éªŒè¯æ¨¡å‹é€‰æ‹©ç»“æœ Validate model selection results
                if len(best_models) != features.shape[0]:
                    raise ValueError(f"æœ€ä½³æ¨¡å‹æ•°é‡({len(best_models)})ä¸ç‰¹å¾æ•°é‡({features.shape[0]})ä¸åŒ¹é…")
                
                # æ­¥éª¤5ï¼šè¯„ä¼°å’Œåé¦ˆ Step 5: Evaluation and feedback
                print("\nğŸ“ˆ æ­¥éª¤5ï¼šç³»ç»Ÿè¯„ä¼°å’Œåé¦ˆ Step 5: System evaluation and feedback")
                evaluation_results = self.evaluate_and_provide_feedback()
                
                # å­˜å‚¨è¿­ä»£ç»“æœ Store iteration results
                iteration_results = {
                    'iteration': self.iteration_count,
                    'features_shape': features.shape,
                    'n_clusters': len(np.unique(cluster_labels)),
                    'classification_accuracy': classification_eval['accuracy'],
                    'best_models': best_models,
                    'evaluation': evaluation_results,
                    'converged': self.converged,
                    'success': True,
                    'error': None
                }
                
                all_results.append(iteration_results)
                
                print(f"\nâœ… è¿­ä»£ {self.iteration_count} æˆåŠŸå®Œæˆ")
                print(f"âœ… Iteration {self.iteration_count} completed successfully")
                print(f"èšç±»å‡†ç¡®åº¦ Clustering accuracy: {classification_eval['accuracy']:.3f}")
                print(f"èšç±»æ•°é‡ Number of clusters: {len(np.unique(cluster_labels))}")
                
                # æ£€æŸ¥æ”¶æ•›æ€§ Check convergence
                if self.converged:
                    print(f"\nğŸŠ ç³»ç»Ÿåœ¨{self.iteration_count}æ¬¡è¿­ä»£åæ”¶æ•›ï¼")
                    print(f"ğŸŠ System converged after {self.iteration_count} iterations!")
                    break
                    
            except Exception as e:
                error_msg = f"è¿­ä»£ {self.iteration_count} å‘ç”Ÿé”™è¯¯: {str(e)}"
                print(f"\nâŒ {error_msg}")
                print(f"âŒ Error in iteration {self.iteration_count}: {str(e)}")
                
                training_errors.append({
                    'iteration': self.iteration_count,
                    'error': str(e),
                    'error_type': type(e).__name__
                })
                
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿­ä»£å¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯
                # If first iteration fails, return error immediately
                if iteration == 0:
                    return {
                        'success': False,
                        'error': error_msg,
                        'total_iterations': self.iteration_count,
                        'training_errors': training_errors,
                        'outlier_info': self.outlier_info
                    }
                
                # å¦åˆ™å°è¯•ç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£
                # Otherwise try to continue with next iteration
                print(f"âš ï¸ å°è¯•ç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£... Attempting to continue with next iteration...")
                continue
        
        # è®­ç»ƒå®Œæˆï¼Œå‡†å¤‡æœ€ç»ˆç»“æœ Training completed, prepare final results
        final_results = {
            'success': True,
            'total_iterations': self.iteration_count,
            'converged': self.converged,
            'outlier_strategy': outlier_strategy,
            'outlier_info': self.outlier_info,
            'data_preprocessing': {
                'outliers_detected': self.outlier_info.get('total_outliers_detected', 0),
                'outliers_replaced': self.outlier_info.get('total_outliers_replaced', 0),
                'preprocessing_applied': outlier_strategy != 'strategy3'
            },
            'final_features': features if 'features' in locals() else None,
            'final_cluster_labels': cluster_labels if 'cluster_labels' in locals() else None,
            'final_best_models': best_models if 'best_models' in locals() else None,
            'iteration_results': all_results,
            'training_errors': training_errors,
            'config': self.config
        }
        
        print("\n" + "=" * 80)
        if final_results['success']:
            print("âœ… ABCMç³»ç»Ÿè®­ç»ƒæˆåŠŸå®Œæˆ ABCM SYSTEM TRAINING COMPLETED SUCCESSFULLY")
        else:
            print("âš ï¸ ABCMç³»ç»Ÿè®­ç»ƒå®Œæˆä½†æœ‰é”™è¯¯ ABCM SYSTEM TRAINING COMPLETED WITH ERRORS")
        print("=" * 80)
        print(f"æ€»è¿­ä»£æ¬¡æ•° Total iterations: {self.iteration_count}")
        print(f"æ˜¯å¦æ”¶æ•› Converged: {'æ˜¯ Yes' if self.converged else 'å¦ No'}")
        print(f"å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier strategy: {outlier_strategy}")
        if hasattr(self, 'outlier_info') and 'total_outliers_detected' in self.outlier_info:
            print(f"å¼‚å¸¸å€¼æ£€æµ‹æ•° Outliers detected: {self.outlier_info['total_outliers_detected']}")
            print(f"å¼‚å¸¸å€¼æ›¿æ¢æ•° Outliers replaced: {self.outlier_info['total_outliers_replaced']}")
        if 'cluster_labels' in locals():
            print(f"æœ€ç»ˆèšç±»æ•° Final clusters: {len(np.unique(cluster_labels))}")
        if training_errors:
            print(f"è®­ç»ƒé”™è¯¯æ•°é‡ Training errors: {len(training_errors)}")
        
        return final_results
    
    def predict(self, data: pd.DataFrame, outlier_strategy: Optional[str] = None) -> Dict[str, Any]:
        """
        å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
        Make predictions on new data
        
        ä½¿ç”¨è®­ç»ƒå¥½çš„ABCMç³»ç»Ÿå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
        Make predictions on new data using trained ABCM system
        
        å‚æ•° Args:
            data (pd.DataFrame): æ–°çš„æ—¶é—´åºåˆ—æ•°æ® New time series data
            outlier_strategy (str, optional): å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy
                                            å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨è®­ç»ƒæ—¶çš„ç­–ç•¥
                                            If None, use the same strategy as training
            
        è¿”å› Returns:
            dict: é¢„æµ‹ç»“æœ Prediction results
        """
        print("=" * 60)
        print("ğŸ”® ABCMç³»ç»Ÿé¢„æµ‹ ABCM SYSTEM PREDICTION")
        print("=" * 60)
        
        # ç¡®å®šå¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Determine outlier handling strategy
        if outlier_strategy is None:
            # ä½¿ç”¨è®­ç»ƒæ—¶çš„ç­–ç•¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ Use training strategy if available
            if hasattr(self, 'outlier_info') and 'strategy' in self.outlier_info:
                outlier_strategy = self.outlier_info['strategy']
            else:
                outlier_strategy = 'strategy3'  # é»˜è®¤ä¸å¤„ç† Default no processing
        
        print(f"å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ Outlier handling strategy: {outlier_strategy}")
        
        # é¢„å¤„ç†æ–°æ•°æ® Preprocess new data
        if outlier_strategy != 'strategy3':
            print("å¯¹æ–°æ•°æ®è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†... Applying outlier handling to new data...")
            try:
                processed_data, outlier_info = self.handle_outliers(data, strategy=outlier_strategy)
                print(f"âœ… æ–°æ•°æ®é¢„å¤„ç†å®Œæˆ New data preprocessing completed")
            except Exception as e:
                print(f"âš ï¸ æ–°æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
                print(f"âš ï¸ New data preprocessing failed, using original data: {e}")
                processed_data = data.copy()
                outlier_info = {'error': str(e)}
        else:
            processed_data = data.copy()
            outlier_info = {'strategy': 'strategy3', 'no_processing': True}
        
        # æå–ç‰¹å¾ Extract features
        print("æå–ç‰¹å¾... Extracting features...")
        features = self.agent1.extract_features(processed_data)
        
        # åˆ†ç±»å¤‡ä»¶ Classify spare parts
        print("åˆ†ç±»å¤‡ä»¶... Classifying spare parts...")
        cluster_labels = self.agent2.predict_new_data(features)
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹ Select best models
        print("é€‰æ‹©æœ€ä½³æ¨¡å‹... Selecting best models...")
        best_models = self.agent3.predict_best_models(features, cluster_labels)
        
        # è·å–æ¨èä¸ç½®ä¿¡åº¦ Get recommendations with confidence
        recommendations = self.agent3.get_model_recommendations(features, cluster_labels)
        
        prediction_results = {
            'features': features,
            'cluster_labels': cluster_labels,
            'best_models': best_models,
            'recommendations': recommendations,
            'outlier_strategy': outlier_strategy,
            'outlier_info': outlier_info,
            'preprocessing_applied': outlier_strategy != 'strategy3',
            'n_spare_parts': len(data.columns),
            'n_clusters': len(np.unique(cluster_labels))
        }
        
        print(f"âœ… é¢„æµ‹å®Œæˆï¼š{len(data.columns)}ä¸ªå¤‡ä»¶ï¼Œ{len(np.unique(cluster_labels))}ä¸ªèšç±»")
        print(f"âœ… Predictions completed: {len(data.columns)} spare parts, {len(np.unique(cluster_labels))} clusters")
        
        if outlier_strategy != 'strategy3' and 'total_outliers_detected' in outlier_info:
            print(f"é¢„æµ‹æ•°æ®å¼‚å¸¸å€¼å¤„ç†ï¼šæ£€æµ‹{outlier_info['total_outliers_detected']}ä¸ªï¼Œæ›¿æ¢{outlier_info['total_outliers_replaced']}ä¸ª")
            print(f"Prediction data outlier handling: detected {outlier_info['total_outliers_detected']}, replaced {outlier_info['total_outliers_replaced']}")
        
        from collections import Counter
        model_counts = Counter(best_models)
        print("æ¨èæ¨¡å‹åˆ†å¸ƒ Recommended model distribution:")
        for model, count in model_counts.items():
            print(f"  {model}: {count}ä¸ªå¤‡ä»¶ spare parts")
        
        return prediction_results
    
    def save_system(self, base_filename: str) -> None:
        """
        ä¿å­˜å®Œæ•´çš„ABCMç³»ç»Ÿ
        Save the complete ABCM system
        
        å‚æ•° Args:
            base_filename (str): ä¿å­˜çš„åŸºæœ¬æ–‡ä»¶å Base filename for saving
        """
        print(f"ä¿å­˜ABCMç³»ç»Ÿ... Saving ABCM system to {base_filename}...")
        
        # ä¿å­˜å„ä¸ªä»£ç† Save individual agents
        self.agent1.save_strategy_pool(f"{base_filename}_agent1.pkl")
        self.agent2.save_model(f"{base_filename}_agent2.pkl")
        self.agent3.save_model(f"{base_filename}_agent3.pkl")
        
        # ä¿å­˜ç³»ç»ŸçŠ¶æ€ Save system state
        system_state = {
            'features': self.features,
            'cluster_labels': self.cluster_labels,
            'model_errors': self.model_errors,
            'best_models': self.best_models,
            'iteration_count': self.iteration_count,
            'converged': self.converged,
            'config': self.config
        }
        
        FileUtils.save_pickle(system_state, f"{base_filename}_system.pkl")
        
        print(f"âœ… ABCMç³»ç»Ÿå·²ä¿å­˜ï¼ŒåŸºæœ¬æ–‡ä»¶å: {base_filename}")
        print(f"âœ… ABCM system saved with base filename: {base_filename}")
    
    def load_system(self, base_filename: str) -> None:
        """
        åŠ è½½ä¹‹å‰ä¿å­˜çš„ABCMç³»ç»Ÿ
        Load a previously saved ABCM system
        
        å‚æ•° Args:
            base_filename (str): åŠ è½½çš„åŸºæœ¬æ–‡ä»¶å Base filename for loading
        """
        print(f"åŠ è½½ABCMç³»ç»Ÿ... Loading ABCM system from {base_filename}...")
        
        # åŠ è½½å„ä¸ªä»£ç† Load individual agents
        self.agent1.load_strategy_pool(f"{base_filename}_agent1.pkl")
        self.agent2.load_model(f"{base_filename}_agent2.pkl")
        self.agent3.load_model(f"{base_filename}_agent3.pkl")
        
        # åŠ è½½ç³»ç»ŸçŠ¶æ€ Load system state
        system_state = FileUtils.load_pickle(f"{base_filename}_system.pkl")
        
        self.features = system_state['features']
        self.cluster_labels = system_state['cluster_labels']
        self.model_errors = system_state['model_errors']
        self.best_models = system_state['best_models']
        self.iteration_count = system_state['iteration_count']
        self.converged = system_state['converged']
        self.config = system_state['config']
        
        print(f"âœ… ABCMç³»ç»Ÿå·²ä»{base_filename}åŠ è½½å®Œæˆ")
        print(f"âœ… ABCM system loaded from {base_filename}")


def main():
    """
    ABCMç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
    Example usage of the ABCM system
    """
    print("ABCMç³»ç»Ÿç¤ºä¾‹ ABCM System Example")
    print("=" * 50)
    
    # åŠ è½½é…ç½® Load configuration
    config = get_config()
    
    # æ–¹æ³•1ï¼šä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨(æ¨è) Method 1: Using pretrained meta-learner (Recommended)
    print("\nğŸ¯ æ–¹æ³•1ï¼šä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Method 1: Using pretrained meta-learner")
    print("æ³¨æ„ï¼šé¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨åº”é€šè¿‡Cross-validation.pyè®­ç»ƒç”Ÿæˆ")
    print("Note: Pretrained meta-learner should be generated through Cross-validation.py training")
    
    # ç¤ºä¾‹å…ƒå­¦ä¹ å™¨è·¯å¾„(è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„) Example meta-learner path (replace with actual path)
    metalearner_path = "experiments/pretrained_metalearner.pkl"  # æˆ– .pkl æ–‡ä»¶
    
    # åˆå§‹åŒ–ABCMç³»ç»Ÿï¼Œä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Initialize ABCM system with pretrained meta-learner
    # abcm_with_metalearner = ABCMSystem(config, pretrained_metalearner_path=metalearner_path)
    
    # æ–¹æ³•2ï¼šä½¿ç”¨å®æ—¶å…ƒå­¦ä¹ (å›é€€é€‰é¡¹) Method 2: Using real-time meta-learning (Fallback option)
    print("\nâš™ï¸  æ–¹æ³•2ï¼šä½¿ç”¨å®æ—¶å…ƒå­¦ä¹  Method 2: Using real-time meta-learning")
    
    # åˆå§‹åŒ–ABCMç³»ç»Ÿï¼Œä¸ä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Initialize ABCM system without pretrained meta-learner
    abcm = ABCMSystem(config)
    
    print("\n" + "=" * 80)
    print("ğŸ”§ å¼‚å¸¸å€¼å¤„ç†åŠŸèƒ½è¯´æ˜ OUTLIER HANDLING FUNCTIONALITY")
    print("=" * 80)
    print("ABCMç³»ç»Ÿç°åœ¨æ”¯æŒä¸‰ç§å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ï¼š")
    print("ABCM system now supports three outlier handling strategies:")
    print()
    print("ğŸ“Š ç­–ç•¥1 (strategy1) - æ¨è Recommended:")
    print("  - ä½¿ç”¨éé›¶éœ€æ±‚çš„MAD (Median Absolute Deviation) ä½œä¸ºæ›¿ä»£å‡å€¼")
    print("  - Use MAD of non-zero demand as substitute mean")
    print("  - ä½¿ç”¨éé›¶éœ€æ±‚æ ‡å‡†å·®æ›¿ä»£æ ‡å‡†å·®")
    print("  - Use non-zero demand standard deviation")
    print("  - ä½¿ç”¨éé›¶éœ€æ±‚ä¸­ä½æ•°æ›¿æ¢å¼‚å¸¸å€¼")
    print("  - Replace outliers with non-zero demand median")
    print()
    print("ğŸ“ˆ ç­–ç•¥2 (strategy2) - æ›¿ä»£æ–¹æ¡ˆ Alternative:")
    print("  - ä½¿ç”¨éé›¶éœ€æ±‚å‡å€¼æ›¿ä»£å‡å€¼ï¼Œå…¶ä»–åŒç­–ç•¥1")
    print("  - Use non-zero demand mean, others same as strategy1")
    print()
    print("â­• ç­–ç•¥3 (strategy3) - æ— å¤„ç† No processing:")
    print("  - ä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
    print("  - No outlier processing, use original data")
    print()
    print("ğŸ¯ è‡ªé€‚åº”é˜ˆå€¼è®¡ç®— Adaptive Threshold Calculation:")
    print("  - åŸºäºéé›¶éœ€æ±‚å˜å¼‚ç³»æ•°å¹³æ–¹ä¸ä¸´ç•Œå€¼0.49çš„å…³ç³»")
    print("  - Based on squared coefficient of variation vs critical value 0.49")
    print("  - ä½å˜å¼‚æ€§ï¼šé˜ˆå€¼2.0-2.5ï¼Œæ›´ä¸¥æ ¼çš„å¼‚å¸¸å€¼æ£€æµ‹")
    print("  - Low variability: threshold 2.0-2.5, stricter detection")
    print("  - é«˜å˜å¼‚æ€§ï¼šé˜ˆå€¼2.5-3.5ï¼Œæ›´å®½æ¾çš„å¼‚å¸¸å€¼æ£€æµ‹")
    print("  - High variability: threshold 2.5-3.5, lenient detection")
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹ USAGE EXAMPLES")
    print("=" * 80)
    print("# ç¤ºä¾‹ï¼šåŠ è½½æ•°æ®(è¯·æ›¿æ¢ä¸ºå®é™…æ•°æ®åŠ è½½)")
    print("# Example: Load data (replace with actual data loading)")
    print("# data = pd.read_excel('your_data.xlsx', index_col=0)")
    print()
    print("# æ–¹æ³•1ï¼šä½¿ç”¨ç­–ç•¥1è®­ç»ƒç³»ç»Ÿ(æ¨è)")
    print("# Method 1: Train with strategy1 (Recommended)")
    print("# results = abcm.train(data, outlier_strategy='strategy1')")
    print()
    print("# æ–¹æ³•2ï¼šä½¿ç”¨ç­–ç•¥2è®­ç»ƒç³»ç»Ÿ")
    print("# Method 2: Train with strategy2")
    print("# results = abcm.train(data, outlier_strategy='strategy2')")
    print()
    print("# æ–¹æ³•3ï¼šä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†")
    print("# Method 3: No outlier processing")
    print("# results = abcm.train(data, outlier_strategy='strategy3')")
    print()
    print("# é¢„æµ‹æ—¶ä½¿ç”¨ç›¸åŒç­–ç•¥(è‡ªåŠ¨)")
    print("# Prediction uses same strategy (automatic)")
    print("# predictions = abcm.predict(new_data)")
    print()
    print("# æˆ–è€…æŒ‡å®šä¸åŒçš„é¢„æµ‹ç­–ç•¥")
    print("# Or specify different prediction strategy")
    print("# predictions = abcm.predict(new_data, outlier_strategy='strategy2')")
    print()
    print("# ä¿å­˜è®­ç»ƒå¥½çš„ç³»ç»Ÿ")
    print("# Save the trained system")
    print("# abcm.save_system('trained_abcm_model')")
    
    print("\n" + "=" * 80)
    print("é‡è¦è¯´æ˜ IMPORTANT NOTES:")
    print("=" * 80)
    print("1. å¼‚å¸¸å€¼å¤„ç†ï¼šåŸºäºé—´æ­‡æ€§éœ€æ±‚é¢„æµ‹ç†è®ºçš„ä¿®æ­£z-scoreæ–¹æ³•")
    print("   Outlier handling: Modified z-score method based on intermittent demand theory")
    print("2. è‡ªé€‚åº”é˜ˆå€¼ï¼šå˜å¼‚ç³»æ•°å¹³æ–¹ä¸0.49ä¸´ç•Œå€¼çš„åŠ¨æ€å…³ç³»")
    print("   Adaptive threshold: Dynamic relationship of CVÂ² with critical value 0.49")
    print("3. é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ï¼šæ¥æºäºexperiments/Cross-validation meta-learning-lightgbm.py")
    print("   Pretrained meta-learner: From experiments/Cross-validation meta-learning-lightgbm.py")
    print("4. å…ƒå­¦ä¹ å™¨ï¼šä½¿ç”¨RandomForest/LightGBMå­¦ä¹ ç‰¹å¾-æ¨¡å‹åŒ¹é…å…³ç³»")
    print("   Meta-learner: Uses RandomForest/LightGBM to learn feature-model mapping")
    print("5. å¤„ç†ç­–ç•¥ï¼šæ¨èç­–ç•¥1ï¼Œé€‚ç”¨äºå¤§å¤šæ•°é—´æ­‡æ€§éœ€æ±‚åœºæ™¯")
    print("   Processing strategy: Strategy1 recommended for most intermittent demand scenarios")
    
    print("\nABCMç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼ ABCM system initialized successfully!")
    print("ç°åœ¨æ”¯æŒæ™ºèƒ½å¼‚å¸¸å€¼å¤„ç†åŠŸèƒ½ï¼ Now supports intelligent outlier handling!")


if __name__ == "__main__":
    main() 