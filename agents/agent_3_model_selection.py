"""
æ¨¡å‹é€‰æ‹©ä»£ç† (Agent 3) - Model Selection Agent

è¯¥ä»£ç†ç»“åˆä»£ç†1çš„ç‰¹å¾å’Œä»£ç†2çš„èšç±»æ ‡ç­¾ï¼Œä½¿ç”¨LightGBMå…ƒå­¦ä¹ è¯†åˆ«æœ€é€‚åˆçš„é¢„æµ‹æ¨¡å‹
This agent combines features from Agent 1 and clustering labels from Agent 2,
using LightGBM meta-learning to identify the most suitable forecasting model

ä¸»è¦åŠŸèƒ½ Main Functions:
- å…ƒå­¦ä¹ æ•°æ®å‡†å¤‡ Meta-learning data preparation
- LightGBMæ¨¡å‹è®­ç»ƒ LightGBM model training
- æœ€ä½³æ¨¡å‹é¢„æµ‹ Best model prediction
- é”™è¯¯é˜ˆå€¼è¯„ä¼° Error threshold evaluation
- å‘ä»£ç†1æä¾›åé¦ˆ Provide feedback to Agent 1

ä½œè€… Author: ABCM Team
åˆ›å»ºæ—¶é—´ Created: 2024
"""

import warnings
import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
import time
import os

warnings.filterwarnings("ignore")


class ModelSelectionAgent:
    """
    ä»£ç†3ï¼šæ¨¡å‹é€‰æ‹©ä»£ç†
    Agent 3: Model Selection Agent
    
    è¯¥ä»£ç†æ˜¯ABCMç³»ç»Ÿçš„å†³ç­–ä¸­å¿ƒï¼Œè´Ÿè´£ä¸ºæ¯ä¸ªå¤‡ä»¶é€‰æ‹©æœ€é€‚åˆçš„é¢„æµ‹æ¨¡å‹
    This agent is the decision center of the ABCM system, responsible for selecting 
    the most suitable forecasting model for each spare part
    
    æ ¸å¿ƒæŠ€æœ¯ Core Technologies:
    1. é¢„è®­ç»ƒæ¨¡å‹åŒ¹é…å…³ç³»å»ºç«‹ - é€šè¿‡ç»¼åˆæ¨¡å‹è¯„ä¼°å»ºç«‹ç‰¹å¾-æ¨¡å‹æ˜ å°„
       Pretrained model mapping establishment - Establish feature-model mapping through comprehensive model evaluation
       
    2. å…ƒå­¦ä¹  - å­¦ä¹ å¦‚ä½•ä¸ºä¸åŒç±»å‹çš„æ•°æ®é€‰æ‹©æœ€ä½³æ¨¡å‹
       Meta-learning - Learn how to select the best model for different types of data
       
    3. LightGBM - é«˜æ•ˆçš„æ¢¯åº¦æå‡å†³ç­–æ ‘ç®—æ³•
       LightGBM - Efficient gradient boosting decision tree algorithm
       
    4. é”™è¯¯è·Ÿè¸ª - ç›‘æ§é¢„æµ‹æ€§èƒ½å¹¶è§¦å‘åé¦ˆè°ƒæ•´
       Error tracking - Monitor prediction performance and trigger feedback adjustments
       
    5. æ¨¡å‹æ¨è - ä¸ºæ–°æ•°æ®æä¾›æ™ºèƒ½æ¨¡å‹é€‰æ‹©
       Model recommendation - Provide intelligent model selection for new data
    
    æ¨¡å‹åŒ¹é…å…³ç³»è·å–è¿‡ç¨‹ Model Matching Relationship Acquisition Process:
    ========================================================================
    åˆå§‹é˜¶æ®µé€šè¿‡ä»¥ä¸‹æ­¥éª¤å»ºç«‹ç‰¹å¾-æ¨¡å‹åŒ¹é…å…³ç³»ï¼ˆå‚è€ƒABCM_RAF.pyå®ç°ï¼‰ï¼š
    Initial phase establishes feature-model matching relationships through these steps (refer to ABCM_RAF.py):
    
    1. æ•°æ®å‡†å¤‡é˜¶æ®µ Data Preparation:
       - æå–ç‰¹å¾ï¼šä½¿ç”¨Agent 1æå–F1-F9ä¸“å®¶ç‰¹å¾å’Œè‡ªç¼–ç å™¨ç‰¹å¾
       - èšç±»åˆ†æï¼šä½¿ç”¨Agent 2è¿›è¡ŒKScorerèšç±»ï¼Œå°†å¤‡ä»¶åˆ†ä¸ºä¸åŒéœ€æ±‚æ¨¡å¼ç±»åˆ«
       - Extract features: Use Agent 1 to extract F1-F9 expert features and autoencoder features
       - Clustering: Use Agent 2 for KScorer clustering, categorizing spare parts into different demand pattern categories
    
    2. ç»¼åˆæ¨¡å‹è¯„ä¼°é˜¶æ®µ Comprehensive Model Evaluation:
       - å€™é€‰æ¨¡å‹ï¼šDeepAR, SBJ, ETS, DeepRenewal (Flat/Exact/Hybrid), ARIMAç­‰
       - åˆ†ç±»åˆ«è¯„ä¼°ï¼šå¯¹æ¯ä¸ªèšç±»ç±»åˆ«çš„å¤‡ä»¶ï¼Œåˆ†åˆ«è®­ç»ƒå’Œæµ‹è¯•æ‰€æœ‰å€™é€‰é¢„æµ‹æ¨¡å‹
       - é”™è¯¯æŒ‡æ ‡è®¡ç®—ï¼šä½¿ç”¨IntermittentEvaluatorè®¡ç®—MRAE, MASE, MAAPE, MAEç­‰æŒ‡æ ‡
       - å¤šè½®éªŒè¯ï¼šè¿›è¡Œå¤šè½®(å¦‚10è½®)è®­ç»ƒå’Œè¯„ä¼°ï¼Œç¡®ä¿ç»“æœç¨³å®šæ€§
       - Candidate models: DeepAR, SBJ, ETS, DeepRenewal (Flat/Exact/Hybrid), ARIMA, etc.
       - Category-wise evaluation: For spare parts in each cluster category, train and test all candidate forecasting models
       - Error metrics calculation: Use IntermittentEvaluator to calculate MRAE, MASE, MAAPE, MAE metrics
       - Multiple rounds validation: Conduct multiple rounds (e.g., 10 rounds) of training and evaluation for stable results
    
    3. æœ€ä½³æ¨¡å‹è¯†åˆ«é˜¶æ®µ Best Model Identification:
       - é”™è¯¯çŸ©é˜µç”Ÿæˆï¼šä¸ºæ¯ä¸ªå¤‡ä»¶ç”ŸæˆåŒ…å«æ‰€æœ‰æ¨¡å‹é”™è¯¯çš„çŸ©é˜µ
       - æœ€ä¼˜é€‰æ‹©ï¼šåŸºäºæœ€å°é”™è¯¯åŸåˆ™ï¼Œä¸ºæ¯ä¸ªå¤‡ä»¶ç¡®å®šæœ€ä½³é¢„æµ‹æ¨¡å‹
       - æ¨¡å¼å‘ç°ï¼šåˆ†æç‰¹å¾æ¨¡å¼ä¸æœ€ä½³æ¨¡å‹é€‰æ‹©ä¹‹é—´çš„å…³ç³»
       - Error matrix generation: Generate matrix containing all model errors for each spare part  
       - Optimal selection: Determine best forecasting model for each spare part based on minimum error principle
       - Pattern discovery: Analyze relationships between feature patterns and optimal model selections
    
    4. å…ƒå­¦ä¹ å™¨è®­ç»ƒé˜¶æ®µ Meta-learner Training:
       - æ•°æ®èåˆï¼šå°†ç‰¹å¾æ•°æ®ä¸æœ€ä½³æ¨¡å‹æ ‡ç­¾ç»“åˆå½¢æˆå…ƒå­¦ä¹ æ•°æ®é›†
       - äº¤å‰éªŒè¯è®­ç»ƒï¼šä½¿ç”¨RandomForest + GridSearchCVè¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–å’Œäº¤å‰éªŒè¯
       - å…³ç³»å­¦ä¹ ï¼šå­¦ä¹ ä»ç‰¹å¾ç©ºé—´(F1-F9 + è‡ªç¼–ç å™¨ + èšç±»æ ‡ç­¾)åˆ°æœ€ä½³æ¨¡å‹çš„æ˜ å°„
       - Data fusion: Combine feature data with best model labels to form meta-learning dataset
       - Cross-validation training: Use RandomForest + GridSearchCV for hyperparameter optimization and cross-validation
       - Relationship learning: Learn mapping from feature space (F1-F9 + autoencoder + cluster labels) to best models
    
    è¿™ç§æ–¹æ³•ç¡®ä¿äº†æ¨¡å‹é€‰æ‹©å†³ç­–åŸºäºå®é™…çš„é¢„æµ‹æ€§èƒ½è¯„ä¼°ï¼Œè€Œéä»»æ„è§„åˆ™æˆ–å‡è®¾ã€‚
    This approach ensures model selection decisions are based on actual forecasting performance evaluation rather than arbitrary rules or assumptions.
    """
    
    def __init__(self, error_threshold=None, models_list=None, pretrained_metalearner_path=None):
        """
        åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©ä»£ç†
        Initialize the Model Selection Agent
        
        å‚æ•° Args:
            error_threshold (float): é”™è¯¯é˜ˆå€¼ Error threshold for triggering feedback
            models_list (list): å€™é€‰é¢„æµ‹æ¨¡å‹åˆ—è¡¨ List of candidate forecasting models
            pretrained_metalearner_path (str): é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è·¯å¾„ Path to pretrained meta-learner from Cross-validation training
        """
        self.error_threshold = error_threshold or 1.5
        self.models_list = models_list or ['DeepAR', 'SBJ', 'ETS', 'DeepRenewal']
        
        # é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ç›¸å…³ Pretrained meta-learner related
        self.pretrained_metalearner_path = pretrained_metalearner_path
        self.pretrained_metalearner = None
        self.pretrained_label_encoder = None
        self.use_pretrained = False
        
        # å®æ—¶å…ƒå­¦ä¹ ç›¸å…³ Real-time meta-learning related
        self.meta_learner = None
        self.label_encoder = None
        self.feature_columns = None
        
        # Load pretrained meta-learner if provided
        if pretrained_metalearner_path and os.path.exists(pretrained_metalearner_path):
            self.load_pretrained_metalearner(pretrained_metalearner_path)
        
        print(f"æ¨¡å‹é€‰æ‹©ä»£ç†åˆå§‹åŒ–å®Œæˆ")
        print(f"Model Selection Agent initialized")
        print(f"é”™è¯¯é˜ˆå€¼ Error threshold: {self.error_threshold}")
        print(f"å€™é€‰æ¨¡å‹ Candidate models: {len(self.models_list)}")
        if self.use_pretrained:
            print(f"âœ… å·²åŠ è½½é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Loaded pretrained meta-learner from: {pretrained_metalearner_path}")
        else:
            print(f"âš ï¸  æœªä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ï¼Œå°†ä½¿ç”¨å®æ—¶è®­ç»ƒ No pretrained meta-learner, will use real-time training")
        
    def load_pretrained_metalearner(self, metalearner_path):
        """
        åŠ è½½ä»Cross-validation meta-learningè®­ç»ƒå¾—åˆ°çš„é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨
        Load pretrained meta-learner from Cross-validation meta-learning training
        
        å‚æ•° Args:
            metalearner_path (str): å…ƒå­¦ä¹ å™¨æ–‡ä»¶è·¯å¾„ Path to meta-learner file
        """
        try:
            import pickle
            
            with open(metalearner_path, 'rb') as f:
                pretrained_data = pickle.load(f)
            
            self.pretrained_metalearner = pretrained_data['meta_learner']
            self.pretrained_label_encoder = pretrained_data['label_encoder']
            self.feature_columns = pretrained_data.get('feature_columns', None)
            
            self.use_pretrained = True
            
            print("âœ… é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨åŠ è½½æˆåŠŸ Pretrained meta-learner loaded successfully")
            print(f"æ¨¡å‹ç±»å‹ Model type: {type(self.pretrained_metalearner).__name__}")
            print(f"æ ‡ç­¾ç¼–ç å™¨ç±»åˆ« Label encoder classes: {self.pretrained_label_encoder.classes_}")
            
            # å¦‚æœæ˜¯GridSearchCVå¯¹è±¡ï¼Œæ˜¾ç¤ºæœ€ä½³å‚æ•°
            if hasattr(self.pretrained_metalearner, 'best_params_'):
                print(f"æœ€ä½³å‚æ•° Best parameters: {self.pretrained_metalearner.best_params_}")
            
        except Exception as e:
            print(f"âŒ é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨åŠ è½½å¤±è´¥ Failed to load pretrained meta-learner: {e}")
            print("å°†å›é€€åˆ°å®æ—¶å…ƒå­¦ä¹ æ¨¡å¼ Falling back to real-time meta-learning mode")
            self.use_pretrained = False
    
    def predict_best_models_with_pretrained(self, features, cluster_labels):
        """
        ä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨é¢„æµ‹æœ€ä½³æ¨¡å‹
        Predict best models using pretrained meta-learner
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            cluster_labels (np.array): æ¥è‡ªä»£ç†2çš„èšç±»æ ‡ç­¾ Cluster labels from Agent 2
            
        è¿”å› Returns:
            np.array: é¢„æµ‹çš„æœ€ä½³æ¨¡å‹ Predicted best models
        """
        if not self.use_pretrained or self.pretrained_metalearner is None:
            raise ValueError("é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ä¸å¯ç”¨ Pretrained meta-learner not available")
        
        print("ä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è¿›è¡Œæ¨¡å‹é€‰æ‹© Using pretrained meta-learner for model selection")
        
        # å‡†å¤‡ç‰¹å¾ï¼Œæ·»åŠ èšç±»æ ‡ç­¾ Prepare features with cluster labels
        meta_features = features.copy()
        meta_features['cluster_label'] = cluster_labels
        
        # ç¡®ä¿ç‰¹å¾åˆ—ä¸€è‡´æ€§ - å…³é”®æ”¹è¿› Ensure feature column consistency - Key improvement
        if hasattr(self, 'pretrained_feature_columns') and self.pretrained_feature_columns:
            # æ£€æŸ¥ç¼ºå¤±çš„ç‰¹å¾åˆ— Check for missing feature columns
            missing_cols = set(self.pretrained_feature_columns) - set(meta_features.columns)
            if missing_cols:
                print(f"âš ï¸ è­¦å‘Šï¼šç¼ºå°‘é¢„è®­ç»ƒç‰¹å¾åˆ— {missing_cols}ï¼Œå°†ç”¨0å¡«å……")
                print(f"âš ï¸ Warning: Missing pretrained feature columns {missing_cols}, filling with 0")
                for col in missing_cols:
                    meta_features[col] = 0
            
            # æ£€æŸ¥å¤šä½™çš„ç‰¹å¾åˆ— Check for extra feature columns
            extra_cols = set(meta_features.columns) - set(self.pretrained_feature_columns)
            if extra_cols:
                print(f"â„¹ï¸ ä¿¡æ¯ï¼šå‘ç°é¢å¤–ç‰¹å¾åˆ— {extra_cols}ï¼Œå°†è¢«å¿½ç•¥")
                print(f"â„¹ï¸ Info: Found extra feature columns {extra_cols}, will be ignored")
            
            # æŒ‰é¢„è®­ç»ƒæ—¶çš„åˆ—é¡ºåºé‡æ–°æ’åˆ— Reorder columns according to pretrained order
            try:
                meta_features = meta_features[self.pretrained_feature_columns]
            except KeyError as e:
                print(f"âŒ ç‰¹å¾åˆ—åŒ¹é…å¤±è´¥: {e}")
                print(f"âŒ Feature column matching failed: {e}")
                print(f"é¢„è®­ç»ƒåˆ— Pretrained columns: {self.pretrained_feature_columns}")
                print(f"å½“å‰åˆ— Current columns: {list(meta_features.columns)}")
                raise
        else:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°é¢„è®­ç»ƒç‰¹å¾åˆ—ä¿¡æ¯ï¼Œä½¿ç”¨å½“å‰ç‰¹å¾")
            print("âš ï¸ Warning: Pretrained feature columns not found, using current features")
        
        # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ Use pretrained model for prediction
        y_pred_encoded = self.pretrained_metalearner.predict(meta_features)
        
        # è§£ç é¢„æµ‹ç»“æœ Decode prediction results
        if hasattr(self, 'pretrained_label_encoder') and self.pretrained_label_encoder:
            predicted_models = self.pretrained_label_encoder.inverse_transform(y_pred_encoded)
        else:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°é¢„è®­ç»ƒæ ‡ç­¾ç¼–ç å™¨ï¼Œä½¿ç”¨åŸå§‹é¢„æµ‹ç»“æœ")
            print("âš ï¸ Warning: Pretrained label encoder not found, using raw predictions")
            predicted_models = y_pred_encoded
        
        print(f"åŸºäºé¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨çš„æ¨¡å‹é€‰æ‹©å®Œæˆ Pretrained meta-learner model selection completed")
        print(f"ä¸º {len(predicted_models)} ä¸ªå¤‡ä»¶é€‰æ‹©äº†æ¨¡å‹ Selected models for {len(predicted_models)} spare parts")
        
        from collections import Counter
        model_counts = Counter(predicted_models)
        print("é¢„æµ‹æ¨¡å‹åˆ†å¸ƒ Predicted model distribution:")
        for model, count in model_counts.items():
            print(f"  {model}: {count}ä¸ªå¤‡ä»¶ spare parts")
        
        return np.array(predicted_models)
    
    def prepare_meta_learning_data(self, features, model_errors, cluster_labels):
        """
        å‡†å¤‡å…ƒå­¦ä¹ æ•°æ®ï¼Œç»“åˆç‰¹å¾å’Œæ¨¡å‹é”™è¯¯
        Prepare data for meta-learning by combining features and model errors
        
        å…ƒå­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯"å­¦ä¹ å¦‚ä½•å­¦ä¹ "ï¼Œè¿™é‡Œæˆ‘ä»¬å­¦ä¹ å¦‚ä½•ä¸ºä¸åŒçš„æ•°æ®é€‰æ‹©æœ€ä½³æ¨¡å‹
        The core idea of meta-learning is "learning to learn", here we learn how to select 
        the best model for different data
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            model_errors (pd.DataFrame): ä¸åŒé¢„æµ‹æ¨¡å‹çš„é”™è¯¯ Errors from different forecasting models
            cluster_labels (np.array): æ¥è‡ªä»£ç†2çš„èšç±»æ ‡ç­¾ Cluster labels from Agent 2
            
        è¿”å› Returns:
            tuple: (X_meta, y_meta) å…ƒå­¦ä¹ çš„è¾“å…¥å’Œè¾“å‡º Input and output for meta-learning
        """
        print("å‡†å¤‡å…ƒå­¦ä¹ æ•°æ®... Preparing meta-learning data...")
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ Data consistency check
        if len(features) != len(cluster_labels):
            raise ValueError(f"ç‰¹å¾æ•°é‡ ({len(features)}) ä¸èšç±»æ ‡ç­¾æ•°é‡ ({len(cluster_labels)}) ä¸åŒ¹é…")
        if len(features) != len(model_errors):
            raise ValueError(f"ç‰¹å¾æ•°é‡ ({len(features)}) ä¸æ¨¡å‹é”™è¯¯æ•°é‡ ({len(model_errors)}) ä¸åŒ¹é…")
        
        # ç»“åˆç‰¹å¾ä¸èšç±»æ ‡ç­¾ Combine features with cluster labels
        meta_features = features.copy()
        meta_features['cluster_label'] = cluster_labels
        
        # ä¸ºæ¯ä¸ªå¤‡ä»¶æ‰¾åˆ°æœ€ä½³æ¨¡å‹(æœ€å°é”™è¯¯) Find best model for each spare part (lowest error)
        best_models = []
        for idx in range(len(model_errors)):
            row_errors = model_errors.iloc[idx]
            # æ’é™¤éæ¨¡å‹åˆ— Exclude non-model columns if any
            model_cols = [col for col in row_errors.index if col in self.models_list]
            if model_cols:
                best_model = row_errors[model_cols].idxmin()
                best_models.append(best_model)
            else:
                best_models.append('DeepAR')  # é»˜è®¤å›é€€ Default fallback
        
        # ç¼–ç ç›®æ ‡æ ‡ç­¾ Encode target labels
        self.label_encoder = LabelEncoder()
        y_meta = self.label_encoder.fit_transform(best_models)
        
        # å­˜å‚¨ç‰¹å¾åˆ—ä»¥ä¾›åç»­ä½¿ç”¨ Store feature columns for later use
        self.feature_columns = meta_features.columns.tolist()
        
        print(f"å…ƒå­¦ä¹ æ•°æ®å‡†å¤‡å®Œæˆï¼š{len(meta_features)}ä¸ªæ ·æœ¬ï¼Œ{len(meta_features.columns)}ä¸ªç‰¹å¾")
        print(f"Meta-learning data prepared: {len(meta_features)} samples, {len(meta_features.columns)} features")
        print(f"å­˜å‚¨ç‰¹å¾åˆ— Stored feature columns: {len(self.feature_columns)} columns")
        print(f"ç›®æ ‡æ¨¡å‹åˆ†å¸ƒ Target model distribution:")
        
        from collections import Counter
        model_counts = Counter(best_models)
        for model, count in model_counts.items():
            print(f"  {model}: {count}ä¸ªå¤‡ä»¶ spare parts")
        
        return meta_features, y_meta
    
    def train_meta_learner(self, X_meta, y_meta, use_lightgbm=True, 
                          test_size=0.2, random_state=42):
        """
        è®­ç»ƒå…ƒå­¦ä¹ æ¨¡å‹
        Train the meta-learning model
        
        å…ƒå­¦ä¹ æ¨¡å‹çš„ç›®æ ‡æ˜¯å­¦ä¹ ç‰¹å¾-æ¨¡å‹æ€§èƒ½çš„æ˜ å°„å…³ç³»
        The goal of the meta-learning model is to learn the mapping between features and model performance
        
        å‚æ•° Args:
            X_meta (pd.DataFrame): å…ƒç‰¹å¾ Meta-features
            y_meta (np.array): ç›®æ ‡æ ‡ç­¾(æœ€ä½³æ¨¡å‹) Target labels (best models)
            use_lightgbm (bool): æ˜¯å¦ä½¿ç”¨LightGBMæˆ–éšæœºæ£®æ— Whether to use LightGBM or Random Forest
            test_size (float): æµ‹è¯•é›†æ¯”ä¾‹ Test set proportion
            random_state (int): éšæœºç§å­ Random seed
            
        è¿”å› Returns:
            dict: è®­ç»ƒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡ Training results and performance metrics
        """
        print("å¼€å§‹è®­ç»ƒå…ƒå­¦ä¹ å™¨... Training meta-learner...")
        start_time = time.time()
        
        # æ•°æ®åˆ†å‰² Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_meta, y_meta, test_size=test_size, random_state=random_state
        )
        
        if use_lightgbm:
            print("ä½¿ç”¨LightGBMä½œä¸ºå…ƒå­¦ä¹ å™¨... Using LightGBM as meta-learner...")
            
            # LightGBMå‚æ•° LightGBM parameters
            lgb_params = {
                'objective': 'multiclass',
                'num_class': len(np.unique(y_meta)),
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': random_state
            }
            
            # åˆ›å»ºæ•°æ®é›† Create datasets
            train_data = lgb.Dataset(X_train, label=y_train)
            valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
            
            # è®­ç»ƒæ¨¡å‹ Train model
            self.meta_learner = lgb.train(
                lgb_params,
                train_data,
                valid_sets=[valid_data],
                num_boost_round=100,
                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]
            )
            
            # é¢„æµ‹ Predictions
            y_pred = np.argmax(self.meta_learner.predict(X_test), axis=1)
            
        else:
            print("ä½¿ç”¨éšæœºæ£®æ—ä½œä¸ºå…ƒå­¦ä¹ å™¨... Using Random Forest as meta-learner...")
            
            # éšæœºæ£®æ—è¶…å‚æ•°è°ƒä¼˜ Random Forest with hyperparameter tuning
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4],
                'bootstrap': [True, False]
            }
            
            rf = RandomForestClassifier(random_state=random_state, class_weight="balanced")
            self.meta_learner = GridSearchCV(
                rf, param_grid, cv=5, scoring='accuracy', 
                verbose=0, n_jobs=-1
            )
            
            self.meta_learner.fit(X_train, y_train)
            y_pred = self.meta_learner.predict(X_test)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡ Calculate performance metrics
        accuracy = accuracy_score(y_test, y_pred)
        
        # äº¤å‰éªŒè¯ Cross-validation
        if use_lightgbm:
            # å¯¹äºLightGBMï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡ŒCVè¿‘ä¼¼ For LightGBM, use the trained model for CV approximation
            cv_scores = [accuracy]  # ç®€åŒ–ç‰ˆæœ¬ Simplified for LightGBM
        else:
            cv_scores = cross_val_score(self.meta_learner, X_train, y_train, cv=5)
        
        end_time = time.time()
        
        results = {
            'accuracy': accuracy,
            'cv_mean': np.mean(cv_scores),
            'cv_std': np.std(cv_scores),
            'training_time': end_time - start_time,
            'best_params': getattr(self.meta_learner, 'best_params_', None),
            'classification_report': classification_report(y_test, y_pred)
        }
        
        print(f"å…ƒå­¦ä¹ å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {results['training_time']:.2f}ç§’")
        print(f"Meta-learner training completed in {results['training_time']:.2f} seconds")
        print(f"å‡†ç¡®åº¦ Accuracy: {results['accuracy']:.3f}")
        print(f"äº¤å‰éªŒè¯å¾—åˆ† CV Score: {results['cv_mean']:.3f} Â± {results['cv_std']:.3f}")
        
        return results
    
    def predict_best_models(self, features, cluster_labels):
        """
        ä¸ºæ–°æ•°æ®é¢„æµ‹æœ€ä½³é¢„æµ‹æ¨¡å‹
        Predict the best forecasting model for new data
        
        ä¼˜å…ˆä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨å…ƒå­¦ä¹ 
        Prefer pretrained meta-learner, fallback to meta-learning if unavailable
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            cluster_labels (np.array): æ¥è‡ªä»£ç†2çš„èšç±»æ ‡ç­¾ Cluster labels from Agent 2
            
        è¿”å› Returns:
            np.array: æ¯ä¸ªå¤‡ä»¶çš„é¢„æµ‹æœ€ä½³æ¨¡å‹ Predicted best models for each spare part
        """
        print("\nå¼€å§‹æ¨¡å‹é€‰æ‹©... Starting model selection...")
        
        # ä¼˜å…ˆä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨ Prefer pretrained meta-learner
        if self.use_pretrained and self.pretrained_metalearner is not None:
            print("ğŸ¯ ä½¿ç”¨é¢„è®­ç»ƒå…ƒå­¦ä¹ å™¨è¿›è¡Œæ¨¡å‹é€‰æ‹© Using pretrained meta-learner for model selection")
            return self.predict_best_models_with_pretrained(features, cluster_labels)
        
        # å›é€€åˆ°å®æ—¶å…ƒå­¦ä¹  Fallback to real-time meta-learning
        if self.meta_learner is None:
            raise ValueError("å…ƒå­¦ä¹ å™¨æœªè®­ç»ƒã€‚è¯·å…ˆè°ƒç”¨train_meta_learner()æ–¹æ³•ã€‚Meta-learner not trained. Call train_meta_learner() first.")
        
        print("ğŸ”§ ä½¿ç”¨å®æ—¶å…ƒå­¦ä¹ å™¨è¿›è¡Œæ¨¡å‹é€‰æ‹© Using real-time meta-learner for model selection")
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ Data consistency check
        if len(features) != len(cluster_labels):
            raise ValueError(f"ç‰¹å¾æ•°é‡ ({len(features)}) ä¸èšç±»æ ‡ç­¾æ•°é‡ ({len(cluster_labels)}) ä¸åŒ¹é…")
        
        # å‡†å¤‡å…ƒç‰¹å¾ Prepare meta-features
        meta_features = features.copy()
        meta_features['cluster_label'] = cluster_labels
        
        # ç¡®ä¿ç‰¹å¾åˆ—ä¸€è‡´æ€§ - å…³é”®æ”¹è¿› Ensure feature column consistency - Key improvement
        if hasattr(self, 'feature_columns') and self.feature_columns:
            # æ£€æŸ¥ç¼ºå¤±çš„ç‰¹å¾åˆ— Check for missing feature columns
            missing_cols = set(self.feature_columns) - set(meta_features.columns)
            if missing_cols:
                print(f"âš ï¸ è­¦å‘Šï¼šç¼ºå°‘è®­ç»ƒç‰¹å¾åˆ— {missing_cols}ï¼Œå°†ç”¨0å¡«å……")
                print(f"âš ï¸ Warning: Missing training feature columns {missing_cols}, filling with 0")
                for col in missing_cols:
                    meta_features[col] = 0
            
            # æ£€æŸ¥å¤šä½™çš„ç‰¹å¾åˆ— Check for extra feature columns
            extra_cols = set(meta_features.columns) - set(self.feature_columns)
            if extra_cols:
                print(f"â„¹ï¸ ä¿¡æ¯ï¼šå‘ç°é¢å¤–ç‰¹å¾åˆ— {extra_cols}ï¼Œå°†è¢«å¿½ç•¥")
                print(f"â„¹ï¸ Info: Found extra feature columns {extra_cols}, will be ignored")
            
            # æŒ‰è®­ç»ƒæ—¶çš„åˆ—é¡ºåºé‡æ–°æ’åˆ— Reorder columns according to training order
            try:
                meta_features = meta_features[self.feature_columns]
                print(f"âœ… ç‰¹å¾åˆ—å¯¹é½æˆåŠŸï¼Œä½¿ç”¨ {len(self.feature_columns)} ä¸ªç‰¹å¾")
                print(f"âœ… Feature column alignment successful, using {len(self.feature_columns)} features")
            except KeyError as e:
                print(f"âŒ ç‰¹å¾åˆ—åŒ¹é…å¤±è´¥: {e}")
                print(f"âŒ Feature column matching failed: {e}")
                print(f"è®­ç»ƒåˆ— Training columns: {self.feature_columns}")
                print(f"å½“å‰åˆ— Current columns: {list(meta_features.columns)}")
                raise
        else:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°è®­ç»ƒç‰¹å¾åˆ—ä¿¡æ¯ï¼Œä½¿ç”¨å½“å‰ç‰¹å¾")
            print("âš ï¸ Warning: Training feature columns not found, using current features")
        
        # ä½¿ç”¨å…ƒå­¦ä¹ å™¨è¿›è¡Œé¢„æµ‹ Use meta-learner for prediction
        try:
            if hasattr(self.meta_learner, 'predict'):
                # å¯¹äºsklearnæ¨¡å‹ For sklearn models
                y_pred_encoded = self.meta_learner.predict(meta_features)
            else:
                # å¯¹äºLightGBMæ¨¡å‹ For LightGBM models
                y_pred_proba = self.meta_learner.predict(meta_features)
                y_pred_encoded = np.argmax(y_pred_proba, axis=1)
        except Exception as e:
            print(f"âŒ å…ƒå­¦ä¹ å™¨é¢„æµ‹å¤±è´¥: {e}")
            print(f"âŒ Meta-learner prediction failed: {e}")
            print(f"å…ƒç‰¹å¾å½¢çŠ¶ Meta-features shape: {meta_features.shape}")
            raise
        
        # è§£ç é¢„æµ‹ç»“æœ Decode prediction results
        if hasattr(self, 'label_encoder') and self.label_encoder:
            try:
                predicted_models = self.label_encoder.inverse_transform(y_pred_encoded)
            except Exception as e:
                print(f"âŒ æ ‡ç­¾è§£ç å¤±è´¥: {e}")
                print(f"âŒ Label decoding failed: {e}")
                print(f"é¢„æµ‹ç¼–ç  Predicted encodings: {y_pred_encoded}")
                raise
        else:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°æ ‡ç­¾ç¼–ç å™¨ï¼Œä½¿ç”¨åŸå§‹é¢„æµ‹ç»“æœ")
            print("âš ï¸ Warning: Label encoder not found, using raw predictions")
            predicted_models = y_pred_encoded
        
        print(f"âœ… å®æ—¶å…ƒå­¦ä¹ å™¨æ¨¡å‹é€‰æ‹©å®Œæˆ")
        print(f"âœ… Real-time meta-learner model selection completed")
        print(f"ä¸º {len(predicted_models)} ä¸ªå¤‡ä»¶é€‰æ‹©äº†æ¨¡å‹")
        print(f"Selected models for {len(predicted_models)} spare parts")
        
        # æ˜¾ç¤ºé¢„æµ‹æ¨¡å‹åˆ†å¸ƒ Display predicted model distribution
        from collections import Counter
        model_counts = Counter(predicted_models)
        print("é¢„æµ‹æ¨¡å‹åˆ†å¸ƒ Predicted model distribution:")
        for model, count in model_counts.items():
            print(f"  {model}: {count}ä¸ªå¤‡ä»¶ spare parts")
        
        return np.array(predicted_models)
    
    def calculate_category_errors(self, model_errors, cluster_labels):
        """
        è®¡ç®—æ¯ä¸ªå¤‡ä»¶ç±»åˆ«çš„é¢„æµ‹é”™è¯¯
        Calculate forecasting errors for each category of spare parts
        
        å‚æ•° Args:
            model_errors (pd.DataFrame): æ¯ä¸ªå¤‡ä»¶çš„æ¨¡å‹é”™è¯¯ Model errors for each spare part
            cluster_labels (np.array): èšç±»æ ‡ç­¾ Cluster labels
            
        è¿”å› Returns:
            dict: æŒ‰ç±»åˆ«å’Œæ¨¡å‹åˆ†ç»„çš„å¹³å‡é”™è¯¯ Average errors by category and model
        """
        print("è®¡ç®—ç±»åˆ«é”™è¯¯... Calculating category errors...")
        
        category_errors = {}
        
        # æŒ‰èšç±»æ ‡ç­¾åˆ†ç»„ Group by cluster labels
        df_with_labels = model_errors.copy()
        df_with_labels['cluster_label'] = cluster_labels
        
        grouped = df_with_labels.groupby('cluster_label')
        
        for label, group in grouped:
            model_cols = [col for col in group.columns if col in self.models_list]
            category_errors[label] = group[model_cols].mean().to_dict()
            
            print(f"ç±»åˆ« {label}: {len(group)} ä¸ªå¤‡ä»¶")
            print(f"Category {label}: {len(group)} spare parts")
        
        return category_errors
    
    def evaluate_error_threshold(self, model_errors, predicted_models, cluster_labels):
        """
        è¯„ä¼°é¢„æµ‹é”™è¯¯æ˜¯å¦è¶…è¿‡é˜ˆå€¼å¹¶è§¦å‘åé¦ˆ
        Evaluate if forecasting errors exceed threshold and trigger feedback
        
        å‚æ•° Args:
            model_errors (pd.DataFrame): æ¨¡å‹é”™è¯¯ Model errors
            predicted_models (np.array): é¢„æµ‹çš„æœ€ä½³æ¨¡å‹ Predicted best models
            cluster_labels (np.array): èšç±»æ ‡ç­¾ Cluster labels
            
        è¿”å› Returns:
            dict: è¯„ä¼°ç»“æœå’Œåé¦ˆä¿¡å· Evaluation results and feedback signals
        """
        print("è¯„ä¼°é”™è¯¯é˜ˆå€¼... Evaluating error threshold...")
        
        if self.error_threshold is None:
            # å°†é˜ˆå€¼è®¾ç½®ä¸ºæ‰€æœ‰å•æ¨¡å‹é”™è¯¯çš„å¹³å‡å€¼ Set threshold as mean of all single-model errors
            all_errors = []
            for model in self.models_list:
                if model in model_errors.columns:
                    all_errors.extend(model_errors[model].dropna().tolist())
            self.error_threshold = np.mean(all_errors) if all_errors else 0.1
            
            print(f"è‡ªåŠ¨è®¾ç½®é”™è¯¯é˜ˆå€¼ä¸º: {self.error_threshold:.3f}")
            print(f"Automatically set error threshold to: {self.error_threshold:.3f}")
        
        # è®¡ç®—é¢„æµ‹æ¨¡å‹çš„é”™è¯¯ Calculate errors for predicted models
        predicted_errors = []
        for i, model in enumerate(predicted_models):
            if model in model_errors.columns:
                predicted_errors.append(model_errors.iloc[i][model])
            else:
                predicted_errors.append(self.error_threshold)  # å›é€€å€¼ Fallback
        
        avg_predicted_error = np.mean(predicted_errors)
        exceeds_threshold = avg_predicted_error > self.error_threshold
        
        # è®¡ç®—ç±»åˆ«ç‰¹å®šé”™è¯¯ Calculate category-specific errors
        self.calculate_category_errors(model_errors, cluster_labels)
        
        evaluation = {
            'avg_error': avg_predicted_error,
            'error_threshold': self.error_threshold,
            'exceeds_threshold': exceeds_threshold,
            'category_errors': self.category_errors,
            'num_categories': len(np.unique(cluster_labels)),
            'error_reduction': self.error_threshold - avg_predicted_error
        }
        
        print(f"å¹³å‡é¢„æµ‹é”™è¯¯: {avg_predicted_error:.3f}")
        print(f"Average prediction error: {avg_predicted_error:.3f}")
        print(f"é”™è¯¯é˜ˆå€¼: {self.error_threshold:.3f}")
        print(f"Error threshold: {self.error_threshold:.3f}")
        print(f"æ˜¯å¦è¶…è¿‡é˜ˆå€¼: {exceeds_threshold}")
        print(f"Exceeds threshold: {exceeds_threshold}")
        
        return evaluation
    
    def provide_feedback_to_agent1(self, evaluation):
        """
        å½“é”™è¯¯é˜ˆå€¼è¢«è¶…è¿‡æ—¶å‘ä»£ç†1æä¾›åé¦ˆ
        Provide feedback to Agent 1 when error threshold is exceeded
        
        å‚æ•° Args:
            evaluation (dict): é”™è¯¯è¯„ä¼°ç»“æœ Error evaluation results
            
        è¿”å› Returns:
            dict: ç»™ä»£ç†1çš„åé¦ˆä¿¡å· Feedback signal for Agent 1
        """
        feedback = {
            'error_exceeds_threshold': evaluation['exceeds_threshold'],
            'avg_error': evaluation['avg_error'],
            'error_threshold': evaluation['error_threshold']
        }
        
        if evaluation['exceeds_threshold']:
            # å»ºè®®ç­–ç•¥è°ƒæ•´ Suggest strategy adjustments
            if evaluation['num_categories'] < 3:
                feedback['suggestion'] = 'adjust_autoencoder_dim'
                feedback['message'] = "ç±»åˆ«è¿‡å°‘ï¼Œè€ƒè™‘è°ƒæ•´è‡ªç¼–ç å™¨ç»´åº¦ Too few categories, consider adjusting autoencoder dimension"
            elif evaluation['avg_error'] > 2 * evaluation['error_threshold']:
                feedback['suggestion'] = 'add_features'
                feedback['message'] = "é”™è¯¯è¾ƒé«˜ï¼Œè€ƒè™‘æ·»åŠ æ›´å¤šæ˜¾å¼ç‰¹å¾ High error, consider adding more explicit features"
            else:
                feedback['suggestion'] = 'adjust_autoencoder_dim'
                feedback['message'] = "ä¸­ç­‰é”™è¯¯ï¼Œå°è¯•è°ƒæ•´è‡ªç¼–ç å™¨æ½œåœ¨ç»´åº¦ Moderate error, try adjusting autoencoder latent dimension"
                
            print(f"å‘ä»£ç†1å‘é€åé¦ˆ: {feedback['message']}")
            print(f"Sending feedback to Agent 1: {feedback['message']}")
        else:
            feedback['suggestion'] = 'maintain_strategy'
            feedback['message'] = "é”™è¯¯åœ¨å¯æ¥å—èŒƒå›´å†… Error within acceptable range"
            
            print("æ— éœ€åé¦ˆï¼Œæ€§èƒ½æ»¡è¶³è¦æ±‚ No feedback needed, performance meets requirements")
        
        return feedback
    
    def get_model_recommendations(self, features, cluster_labels):
        """
        è·å–å¤‡ä»¶çš„æ¨¡å‹æ¨è
        Get model recommendations for spare parts
        
        å‚æ•° Args:
            features (pd.DataFrame): æ¥è‡ªä»£ç†1çš„ç‰¹å¾ Features from Agent 1
            cluster_labels (np.array): æ¥è‡ªä»£ç†2çš„èšç±»æ ‡ç­¾ Cluster labels from Agent 2
            
        è¿”å› Returns:
            pd.DataFrame: å¸¦ç½®ä¿¡åº¦åˆ†æ•°çš„æ¨è Recommendations with confidence scores
        """
        predicted_models = self.predict_best_models(features, cluster_labels)
        
        # åˆ›å»ºæ¨èæ•°æ®æ¡† Create recommendations dataframe
        recommendations = pd.DataFrame({
            'spare_part_id': range(len(predicted_models)),
            'cluster_label': cluster_labels,
            'recommended_model': predicted_models
        })
        
        # æ·»åŠ ç½®ä¿¡åº¦åˆ†æ•°(å¦‚æœå¯ç”¨) Add confidence scores if available
        if hasattr(self.meta_learner, 'predict_proba'):
            meta_features = features.copy()
            meta_features['cluster_label'] = cluster_labels
            meta_features = meta_features[self.feature_columns]
            
            probabilities = self.meta_learner.predict_proba(meta_features)
            recommendations['confidence'] = np.max(probabilities, axis=1)
        elif hasattr(self.meta_learner, 'predict'):
            # LightGBMæƒ…å†µ LightGBM case
            meta_features = features.copy()
            meta_features['cluster_label'] = cluster_labels
            meta_features = meta_features[self.feature_columns]
            
            probabilities = self.meta_learner.predict(meta_features)
            if len(probabilities.shape) > 1:
                recommendations['confidence'] = np.max(probabilities, axis=1)
            else:
                recommendations['confidence'] = 0.8  # é»˜è®¤ç½®ä¿¡åº¦ Default confidence
        
        print(f"ç”Ÿæˆäº†{len(recommendations)}ä¸ªæ¨¡å‹æ¨è")
        print(f"Generated {len(recommendations)} model recommendations")
        
        return recommendations
    
    def save_model(self, filename):
        """ä¿å­˜è®­ç»ƒå¥½çš„å…ƒå­¦ä¹ å™¨åˆ°æ–‡ä»¶ Save trained meta-learner to file"""
        import pickle
        model_data = {
            'meta_learner': self.meta_learner,
            'label_encoder': self.label_encoder,
            'feature_columns': self.feature_columns,
            'error_threshold': self.error_threshold,
            'models_list': self.models_list,
            'category_errors': self.category_errors,
            'model_performance': self.model_performance
        }
        
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
            
        print(f"æ¨¡å‹é€‰æ‹©ä»£ç†å·²ä¿å­˜åˆ°: {filename}")
        print(f"Model Selection Agent saved to: {filename}")
    
    def load_model(self, filename):
        """ä»æ–‡ä»¶åŠ è½½è®­ç»ƒå¥½çš„å…ƒå­¦ä¹ å™¨ Load trained meta-learner from file"""
        import pickle
        with open(filename, 'rb') as f:
            model_data = pickle.load(f)
            
        self.meta_learner = model_data['meta_learner']
        self.label_encoder = model_data['label_encoder']
        self.feature_columns = model_data['feature_columns']
        self.error_threshold = model_data['error_threshold']
        self.models_list = model_data['models_list']
        self.category_errors = model_data['category_errors']
        self.model_performance = model_data.get('model_performance', {})
        
        print(f"æ¨¡å‹é€‰æ‹©ä»£ç†å·²ä»{filename}åŠ è½½")
        print(f"Model Selection Agent loaded from {filename}") 