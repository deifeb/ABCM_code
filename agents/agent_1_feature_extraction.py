"""
ç‰¹å¾æå–ä»£ç† (Agent 1) - Feature Extraction Agent

è¯¥ä»£ç†è´Ÿè´£ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æå–ä¸åŒç±»å‹çš„ç‰¹å¾ï¼Œå¹¶å®ç°å¤šç§ç‰¹å¾æå–ç­–ç•¥
This agent is responsible for extracting different types of features from time series data 
and implementing multiple feature extraction strategies

å…­ç§ç‰¹å¾æå–ç­–ç•¥ Six Feature Extraction Strategies:
(1) S_raw: åªä½¿ç”¨åŸå§‹éœ€æ±‚ç‰¹å¾ Only raw demand features
(2) S_expert: åªä½¿ç”¨ä¸“å®¶è¡ç”Ÿç‰¹å¾ Only expert-derived features  
(3) S_auto_opt: åªä½¿ç”¨æœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾ Only autoencoder features with optimal dimensions
(4) S_auto_opt+expert: ç»“åˆæœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾å’Œä¸“å®¶è¡ç”Ÿç‰¹å¾ Combination of optimal autoencoder + expert features
(5) S_auto_multi+expert: ç»“åˆä¸åŒç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾å’Œä¸“å®¶è¡ç”Ÿç‰¹å¾ Combination of multi-dimensional autoencoder + expert features

åŠ¨æ€è°ƒæ•´æœºåˆ¶ Dynamic Adjustment Mechanism:
- åŸºäºä¸‹æ¸¸ä»£ç†çš„é—­ç¯åé¦ˆ Closed-loop feedback from downstream agents
- å½“èšç±»è¯„ä¼°æŒ‡æ ‡<0.9æ—¶è§¦å‘ç­–ç•¥è°ƒæ•´ Strategy adjustment triggered when clustering metric < 0.9
- åŠ¨æ€è°ƒæ•´è‡ªç¼–ç å™¨ç»´åº¦æˆ–é‡æ–°æ¿€æ´»åŸå§‹ç‰¹å¾ Dynamic adjustment of autoencoder dimensions or reactivation of raw features

ä½œè€… Author: ABCM Team
åˆ›å»ºæ—¶é—´ Created: 2024
"""

import os
import warnings
import numpy as np
import pandas as pd
import tensorflow as tf
from collections import Counter
from scipy.stats import variation
import statsmodels.api as sm
import antropy as ant
from typing import Dict, List, Tuple, Optional, Union
import pickle
import json
from datetime import datetime

warnings.filterwarnings("ignore")
os.environ["OMP_NUM_THREADS"] = '3'


class FeatureExtractionAgent:
    """
    ä»£ç†1ï¼šç‰¹å¾æå–ä»£ç† - æ”¯æŒå…­ç§ç‰¹å¾æå–ç­–ç•¥
    Agent 1: Feature Extraction Agent - Supporting Six Feature Extraction Strategies
    
    è¯¥ä»£ç†å®ç°äº†å¤šç§ç‰¹å¾æå–ç­–ç•¥ï¼Œå¹¶å…·å¤‡åŠ¨æ€è°ƒæ•´æœºåˆ¶
    This agent implements multiple feature extraction strategies with dynamic adjustment mechanism
    """
    
    def __init__(self, 
                 encoding_dim: int = 12, 
                 autoencoder_epochs: int = 50, 
                 batch_size: int = 16,
                 multi_dims: List[int] = [8, 12, 16],
                 feedback_threshold: float = 0.9):
        """
        åˆå§‹åŒ–ç‰¹å¾æå–ä»£ç†
        Initialize the Feature Extraction Agent
        
        å‚æ•° Args:
            encoding_dim (int): é»˜è®¤è‡ªç¼–ç å™¨æ½œåœ¨ç©ºé—´ç»´åº¦ Default autoencoder latent space dimension
            autoencoder_epochs (int): è‡ªç¼–ç å™¨è®­ç»ƒè½®æ•° Training epochs for autoencoder
            batch_size (int): æ‰¹å¤„ç†å¤§å° Batch size for autoencoder training
            multi_dims (List[int]): å¤šç»´åº¦è‡ªç¼–ç å™¨ç»´åº¦åˆ—è¡¨ Multi-dimensional autoencoder dimensions
            feedback_threshold (float): åé¦ˆè°ƒæ•´é˜ˆå€¼ Feedback adjustment threshold
        """
        self.encoding_dim = encoding_dim
        self.autoencoder_epochs = autoencoder_epochs
        self.batch_size = batch_size
        self.multi_dims = multi_dims
        self.feedback_threshold = feedback_threshold
        
        # ç­–ç•¥é…ç½® Strategy configuration
        self.strategies = {
            'S_raw': 'raw_demand_only',
            'S_expert': 'expert_features_only', 
            'S_auto_opt': 'autoencoder_optimal_only',
            'S_auto_opt+expert': 'autoencoder_optimal_plus_expert',
            'S_auto_multi+expert': 'autoencoder_multi_plus_expert'
        }
        
        self.current_strategy = 'S_auto_opt+expert'  # é»˜è®¤ç­–ç•¥ Default strategy
        self.strategy_history = []  # ç­–ç•¥è°ƒæ•´å†å² Strategy adjustment history
        self.performance_history = {}  # æ€§èƒ½å†å²è®°å½• Performance history
        
        # æ¨¡å‹å­˜å‚¨ Model storage
        self.autoencoders = {}  # ä¸åŒç»´åº¦çš„è‡ªç¼–ç å™¨ Autoencoders with different dimensions
        self.encoders = {}     # å¯¹åº”çš„ç¼–ç å™¨ Corresponding encoders
        
        # åé¦ˆæœºåˆ¶ Feedback mechanism
        self.feedback_signals = []
        self.adjustment_count = 0
        
        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§ Set random seeds for reproducibility
        np.random.seed(42)
        tf.random.set_seed(42)
        
        print("=" * 80)
        print("ğŸš€ ç‰¹å¾æå–ä»£ç†åˆå§‹åŒ–å®Œæˆ Feature Extraction Agent Initialized")
        print("=" * 80)
        print(f"é»˜è®¤ç­–ç•¥ Default strategy: {self.current_strategy}")
        print(f"æ”¯æŒçš„ç»´åº¦ Supported dimensions: {self.multi_dims}")
        print(f"åé¦ˆé˜ˆå€¼ Feedback threshold: {self.feedback_threshold}")
    
    def extract_raw_demand_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ç­–ç•¥ S_raw: æå–åŸå§‹éœ€æ±‚ç‰¹å¾
        Strategy S_raw: Extract raw demand features
        
        è¿™ç§ç­–ç•¥ç›´æ¥ä½¿ç”¨åŸå§‹éœ€æ±‚æ•°æ®ï¼Œä¿æŒæ•°æ®çš„ç®€å•æ€§å’Œç›´è§‚æ€§
        This strategy directly uses raw demand data, maintaining simplicity and intuitiveness
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            
        è¿”å› Returns:
            pd.DataFrame: åŸå§‹éœ€æ±‚ç‰¹å¾ Raw demand features
        """
        print("ğŸ”¸ æ‰§è¡Œç­–ç•¥ S_raw: æå–åŸå§‹éœ€æ±‚ç‰¹å¾")
        print("ğŸ”¸ Executing Strategy S_raw: Extracting raw demand features")
        
        # ä½¿ç”¨åŸå§‹æ—¶é—´åºåˆ—çš„ç»Ÿè®¡ç‰¹å¾ Use statistical features of raw time series
        raw_features = []
        
        for col in data.columns:
            series = data[col].values
            feature_dict = {
                'mean': np.mean(series),
                'std': np.std(series),
                'max': np.max(series),
                'min': np.min(series),
                'median': np.median(series),
                'skewness': pd.Series(series).skew(),
                'kurtosis': pd.Series(series).kurtosis(),
                'variance': np.var(series),
                'range': np.max(series) - np.min(series),
                'sum': np.sum(series),
                'non_zero_count': np.count_nonzero(series),
                'zero_count': np.sum(series == 0),
                'last_value': series[-1],
                'first_value': series[0],
                'trend_slope': np.polyfit(range(len(series)), series, 1)[0] if len(series) > 1 else 0
            }
            raw_features.append(feature_dict)
        
        raw_features_df = pd.DataFrame(raw_features)
        print(f"âœ… åŸå§‹ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾æ•°: {raw_features_df.shape[1]}")
        print(f"âœ… Raw features extracted, feature count: {raw_features_df.shape[1]}")
        
        return raw_features_df
    
    def compute_expert_features(self, time_series: np.ndarray) -> Dict[str, float]:
        """
        è®¡ç®—ä¸“å®¶çŸ¥è¯†ç‰¹å¾(F1-F9)
        Compute expert knowledge features (F1-F9)
        
        è¿™äº›ç‰¹å¾æ˜¯åŸºäºé—´æ­‡æ€§éœ€æ±‚é¢„æµ‹é¢†åŸŸçš„ä¸“å®¶çŸ¥è¯†è®¾è®¡çš„
        These features are designed based on expert knowledge in intermittent demand forecasting
        
        å‚æ•° Args:
            time_series (np.ndarray): æ—¶é—´åºåˆ—æ•°æ® Time series data
            
        è¿”å› Returns:
            Dict[str, float]: åŒ…å«è®¡ç®—å‡ºçš„ç‰¹å¾çš„å­—å…¸ Dictionary containing computed features
        """
        features = {}

        # F1: å¹³å‡éœ€æ±‚é—´éš” (ADI - Average Demand Interval)
        demand_indices = np.where(time_series > 0)[0]
        if len(demand_indices) > 1:
            inter_demand_intervals = np.diff(demand_indices)
            features['F1'] = np.mean(inter_demand_intervals)
        else:
            features['F1'] = np.nan

        # F2: å˜å¼‚ç³»æ•°çš„å¹³æ–¹ (CVÂ² - Square of Coefficient of Variation)
        non_zero_demand = time_series[time_series > 0]
        if len(non_zero_demand) > 0:
            features['F2'] = variation(non_zero_demand) ** 2
        else:
            features['F2'] = np.nan

        # F3: è¿‘ä¼¼ç†µ (Approximate Entropy)
        try:
            features['F3'] = ant.app_entropy(time_series, order=2)
        except:
            features['F3'] = 0.0

        # F4: é›¶å€¼ç™¾åˆ†æ¯” (Percentage of Zero Values)
        features['F4'] = np.sum(time_series == 0) / len(time_series)

        # F5: è¶…å‡º[å‡å€¼Â±æ ‡å‡†å·®]èŒƒå›´çš„å€¼çš„ç™¾åˆ†æ¯”
        mean_y = np.mean(time_series)
        std_y = np.std(time_series)
        features['F5'] = np.sum((time_series < mean_y - std_y) | 
                               (time_series > mean_y + std_y)) / len(time_series)

        # F6: çº¿æ€§æœ€å°äºŒä¹˜å›å½’ç³»æ•°
        chunk_size = 12
        chunks = [time_series[i:i + chunk_size] 
                 for i in range(0, len(time_series), chunk_size)]
        variances = [np.var(chunk) for chunk in chunks if len(chunk) == chunk_size]
        
        if len(variances) > 1:
            try:
                x = np.arange(len(variances))
                X = sm.add_constant(x)
                model = sm.OLS(variances, X).fit()
                features['F6'] = model.params[1]
            except:
                features['F6'] = 0.0
        else:
            features['F6'] = np.nan

        # F7: è¿ç»­å˜åŒ–çš„å¹³å‡ç»å¯¹å€¼
        consecutive_changes = np.diff(time_series)
        features['F7'] = np.mean(np.abs(consecutive_changes))

        # F8: æœ€åä¸€ä¸ªå—çš„å¹³æ–¹å’Œå æ€»åºåˆ—çš„æ¯”ä¾‹
        k = 4
        chunk_length = len(time_series) // k
        last_chunk = time_series[-chunk_length:]
        total_sum_squares = np.sum(time_series ** 2)
        features['F8'] = np.sum(last_chunk ** 2) / total_sum_squares if total_sum_squares > 0 else 0

        # F9: åºåˆ—æœ«å°¾è¿ç»­é›¶å€¼çš„ç™¾åˆ†æ¯”
        consecutive_zero_at_end = 0
        for value in reversed(time_series):
            if value == 0:
                consecutive_zero_at_end += 1
            else:
                break
        features['F9'] = consecutive_zero_at_end / len(time_series)

        return features
    
    def extract_expert_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ç­–ç•¥ S_expert: æå–ä¸“å®¶è¡ç”Ÿç‰¹å¾
        Strategy S_expert: Extract expert-derived features
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            
        è¿”å› Returns:
            pd.DataFrame: ä¸“å®¶ç‰¹å¾æ•°æ®æ¡† Expert features DataFrame
        """
        print("ğŸ”¹ æ‰§è¡Œç­–ç•¥ S_expert: æå–ä¸“å®¶è¡ç”Ÿç‰¹å¾")
        print("ğŸ”¹ Executing Strategy S_expert: Extracting expert-derived features")
        
        expert_features = []
        for col in data.columns:
            features = self.compute_expert_features(data[col].values)
            expert_features.append(features)
        
        expert_features_df = pd.DataFrame(expert_features)
        print(f"âœ… ä¸“å®¶ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾æ•°: {expert_features_df.shape[1]}")
        print(f"âœ… Expert features extracted, feature count: {expert_features_df.shape[1]}")
        
        return expert_features_df
    
    def build_autoencoder(self, input_shape: Tuple[int], encoding_dim: int) -> Tuple[tf.keras.Model, tf.keras.Model]:
        """
        æ„å»ºæŒ‡å®šç»´åº¦çš„è‡ªç¼–ç å™¨
        Build autoencoder with specified dimension
        
        å‚æ•° Args:
            input_shape (Tuple[int]): è¾“å…¥æ•°æ®çš„å½¢çŠ¶ Shape of input data
            encoding_dim (int): ç¼–ç ç»´åº¦ Encoding dimension
            
        è¿”å› Returns:
            Tuple[tf.keras.Model, tf.keras.Model]: (autoencoder, encoder) è‡ªç¼–ç å™¨å’Œç¼–ç å™¨æ¨¡å‹
        """
        input_layer = tf.keras.layers.Input(shape=input_shape)
        
        # ç¼–ç å™¨éƒ¨åˆ† Encoder part
        encoded = tf.keras.layers.Dense(64, activation='relu')(input_layer)
        encoded = tf.keras.layers.Dense(32, activation='relu')(encoded)
        encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(encoded)
        
        # è§£ç å™¨éƒ¨åˆ† Decoder part  
        decoded = tf.keras.layers.Dense(32, activation='relu')(encoded)
        decoded = tf.keras.layers.Dense(64, activation='relu')(decoded)
        decoded = tf.keras.layers.Dense(input_shape[0], activation='sigmoid')(decoded)
        
        autoencoder = tf.keras.models.Model(input_layer, decoded)
        encoder = tf.keras.models.Model(input_layer, encoded)
        
        autoencoder.compile(optimizer='adam', loss='mse')
        
        return autoencoder, encoder
    
    def extract_autoencoder_features(self, data: pd.DataFrame, encoding_dim: int) -> pd.DataFrame:
        """
        ä½¿ç”¨æŒ‡å®šç»´åº¦çš„è‡ªç¼–ç å™¨æå–ç‰¹å¾
        Extract features using autoencoder with specified dimension
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            encoding_dim (int): ç¼–ç ç»´åº¦ Encoding dimension
            
        è¿”å› Returns:
            pd.DataFrame: è‡ªç¼–ç å™¨ç‰¹å¾ Autoencoder features
        """
        input_data = data.T.values
        sequence_length = input_data.shape[1]
        input_shape = (sequence_length,)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥ç»´åº¦çš„æ¨¡å‹ Check if model with this dimension already exists
        dim_key = f"dim_{encoding_dim}"
        if dim_key not in self.autoencoders:
            print(f"ğŸ”§ æ„å»º {encoding_dim} ç»´è‡ªç¼–ç å™¨...")
            print(f"ğŸ”§ Building {encoding_dim}-dimension autoencoder...")
            
            autoencoder, encoder = self.build_autoencoder(input_shape, encoding_dim)
            
            print(f"ğŸ”„ è®­ç»ƒ {encoding_dim} ç»´è‡ªç¼–ç å™¨...")
            print(f"ğŸ”„ Training {encoding_dim}-dimension autoencoder...")
            
            autoencoder.fit(
                input_data, input_data,
                epochs=self.autoencoder_epochs,
                batch_size=self.batch_size,
                verbose=0
            )
            
            self.autoencoders[dim_key] = autoencoder
            self.encoders[dim_key] = encoder
        
        # æå–ç‰¹å¾ Extract features
        encoder = self.encoders[dim_key]
        encoded_data = encoder.predict(input_data, verbose=0)
        
        feature_columns = [f'AutoEnc_{encoding_dim}D_F{i}' for i in range(1, encoding_dim + 1)]
        autoencoder_features = pd.DataFrame(encoded_data, columns=feature_columns)
        
        return autoencoder_features
    
    def extract_autoencoder_optimal_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ç­–ç•¥ S_auto_opt: æå–æœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾
        Strategy S_auto_opt: Extract autoencoder features with optimal dimensions
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            
        è¿”å› Returns:
            pd.DataFrame: æœ€ä¼˜ç»´åº¦è‡ªç¼–ç å™¨ç‰¹å¾ Optimal autoencoder features
        """
        print("ğŸ”¹ æ‰§è¡Œç­–ç•¥ S_auto_opt: æå–æœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾")
        print("ğŸ”¹ Executing Strategy S_auto_opt: Extracting optimal autoencoder features")
        
        return self.extract_autoencoder_features(data, self.encoding_dim)
    
    def extract_autoencoder_multi_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        æå–å¤šç»´åº¦è‡ªç¼–ç å™¨ç‰¹å¾
        Extract multi-dimensional autoencoder features
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            
        è¿”å› Returns:
            pd.DataFrame: å¤šç»´åº¦è‡ªç¼–ç å™¨ç‰¹å¾ Multi-dimensional autoencoder features
        """
        print("ğŸ”¹ æå–å¤šç»´åº¦è‡ªç¼–ç å™¨ç‰¹å¾...")
        print("ğŸ”¹ Extracting multi-dimensional autoencoder features...")
        
        all_features = []
        for dim in self.multi_dims:
            features = self.extract_autoencoder_features(data, dim)
            all_features.append(features)
        
        multi_features = pd.concat(all_features, axis=1)
        print(f"âœ… å¤šç»´åº¦è‡ªç¼–ç å™¨ç‰¹å¾æå–å®Œæˆï¼Œæ€»ç‰¹å¾æ•°: {multi_features.shape[1]}")
        print(f"âœ… Multi-dimensional autoencoder features extracted, total features: {multi_features.shape[1]}")
        
        return multi_features
    
    def extract_features_by_strategy(self, data: pd.DataFrame, strategy: str = None) -> pd.DataFrame:
        """
        æ ¹æ®æŒ‡å®šç­–ç•¥æå–ç‰¹å¾
        Extract features according to specified strategy
        
        å‚æ•° Args:
            data (pd.DataFrame): è¾“å…¥æ—¶é—´åºåˆ—æ•°æ® Input time series data
            strategy (str): ç‰¹å¾æå–ç­–ç•¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰ç­–ç•¥ Feature extraction strategy
            
        è¿”å› Returns:
            pd.DataFrame: æå–çš„ç‰¹å¾ Extracted features
        """
        if strategy is None:
            strategy = self.current_strategy
        
        print("=" * 80)
        print(f"ğŸ¯ æ‰§è¡Œç‰¹å¾æå–ç­–ç•¥: {strategy}")
        print(f"ğŸ¯ Executing feature extraction strategy: {strategy}")
        print("=" * 80)
        
        features_list = []
        
        if strategy == 'S_raw':
            # ç­–ç•¥1: åªä½¿ç”¨åŸå§‹éœ€æ±‚ç‰¹å¾
            features_list.append(self.extract_raw_demand_features(data))
            
        elif strategy == 'S_expert':
            # ç­–ç•¥2: åªä½¿ç”¨ä¸“å®¶è¡ç”Ÿç‰¹å¾
            features_list.append(self.extract_expert_features(data))
            
        elif strategy == 'S_auto_opt':
            # ç­–ç•¥3: åªä½¿ç”¨æœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾
            features_list.append(self.extract_autoencoder_optimal_features(data))
            
        elif strategy == 'S_auto_opt+expert':
            # ç­–ç•¥4: ç»“åˆæœ€åˆé€‚ç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾å’Œä¸“å®¶è¡ç”Ÿç‰¹å¾
            features_list.append(self.extract_autoencoder_optimal_features(data))
            features_list.append(self.extract_expert_features(data))
            
        elif strategy == 'S_auto_multi+expert':
            # ç­–ç•¥5: ç»“åˆä¸åŒç»´åº¦çš„è‡ªç¼–ç å™¨ç‰¹å¾å’Œä¸“å®¶è¡ç”Ÿç‰¹å¾
            features_list.append(self.extract_autoencoder_multi_features(data))
            features_list.append(self.extract_expert_features(data))
            
        else:
            raise ValueError(f"æœªçŸ¥çš„ç­–ç•¥: {strategy}. æ”¯æŒçš„ç­–ç•¥: {list(self.strategies.keys())}")
        
        # åˆå¹¶ç‰¹å¾ Combine features
        if len(features_list) == 1:
            final_features = features_list[0]
        else:
            final_features = pd.concat(features_list, axis=1)
        
        # è®°å½•ç­–ç•¥ä½¿ç”¨ Record strategy usage
        self.strategy_history.append({
            'timestamp': datetime.now().isoformat(),
            'strategy': strategy,
            'feature_count': final_features.shape[1],
            'data_shape': data.shape
        })
        
        print("=" * 80)
        print(f"âœ… ç‰¹å¾æå–å®Œæˆ Feature extraction completed")
        print(f"ğŸ“Š ä½¿ç”¨ç­–ç•¥: {strategy}")
        print(f"ğŸ“Š Strategy used: {strategy}")
        print(f"ğŸ“ˆ æ€»ç‰¹å¾æ•°: {final_features.shape[1]}")
        print(f"ğŸ“ˆ Total features: {final_features.shape[1]}")
        print(f"ğŸ“‹ æ•°æ®å½¢çŠ¶: {data.shape} -> {final_features.shape}")
        print(f"ğŸ“‹ Data shape: {data.shape} -> {final_features.shape}")
        print("=" * 80)
        
        return final_features
    
    def receive_feedback(self, feedback_signal: Dict[str, Union[float, str, Dict]]):
        """
        æ¥æ”¶æ¥è‡ªä¸‹æ¸¸ä»£ç†çš„åé¦ˆä¿¡å·
        Receive feedback signal from downstream agents
        
        å‚æ•° Args:
            feedback_signal (Dict): åé¦ˆä¿¡å·
                - clustering_score (float): èšç±»è¯„ä¼°åˆ†æ•°
                - forecasting_errors (Dict): å„ç±»åˆ«çš„é¢„æµ‹è¯¯å·®
                - suggestion (str): è°ƒæ•´å»ºè®®
                - category_performance (Dict): å„ç±»åˆ«æ€§èƒ½
        """
        print("\n" + "ğŸ”„" * 60)
        print("æ¥æ”¶åé¦ˆä¿¡å· Receiving feedback signal")
        print("ğŸ”„" * 60)
        
        self.feedback_signals.append({
            'timestamp': datetime.now().isoformat(),
            'signal': feedback_signal,
            'current_strategy': self.current_strategy
        })
        
        clustering_score = feedback_signal.get('clustering_score', 1.0)
        forecasting_errors = feedback_signal.get('forecasting_errors', {})
        suggestion = feedback_signal.get('suggestion', '')
        
        print(f"ğŸ“Š èšç±»è¯„ä¼°åˆ†æ•°: {clustering_score:.3f}")
        print(f"ğŸ“Š Clustering score: {clustering_score:.3f}")
        print(f"ğŸ’¡ è°ƒæ•´å»ºè®®: {suggestion}")
        print(f"ğŸ’¡ Suggestion: {suggestion}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥ Determine if strategy adjustment is needed
        if clustering_score < self.feedback_threshold:
            print(f"âš ï¸ èšç±»åˆ†æ•° {clustering_score:.3f} ä½äºé˜ˆå€¼ {self.feedback_threshold}")
            print(f"âš ï¸ Clustering score {clustering_score:.3f} below threshold {self.feedback_threshold}")
            self.adjust_strategy(feedback_signal)
        
        # æ£€æŸ¥é¢„æµ‹è¯¯å·® Check forecasting errors
        if forecasting_errors:
            high_error_categories = [cat for cat, error in forecasting_errors.items() 
                                   if error > 5.0]  # å‡è®¾è¯¯å·®é˜ˆå€¼ä¸º5.0
            if high_error_categories:
                print(f"âš ï¸ é«˜è¯¯å·®ç±»åˆ«: {high_error_categories}")
                print(f"âš ï¸ High error categories: {high_error_categories}")
                self.adjust_for_high_errors(high_error_categories, forecasting_errors)
    
    def adjust_strategy(self, feedback_signal: Dict[str, Union[float, str, Dict]]):
        """
        æ ¹æ®åé¦ˆè°ƒæ•´ç‰¹å¾æå–ç­–ç•¥
        Adjust feature extraction strategy based on feedback
        
        å‚æ•° Args:
            feedback_signal (Dict): åé¦ˆä¿¡å· Feedback signal
        """
        print("\n" + "ğŸ”§" * 50)
        print("æ‰§è¡Œç­–ç•¥è°ƒæ•´ Executing strategy adjustment")
        print("ğŸ”§" * 50)
        
        old_strategy = self.current_strategy
        suggestion = feedback_signal.get('suggestion', '')
        
        # ç­–ç•¥è°ƒæ•´é€»è¾‘ Strategy adjustment logic
        if suggestion == 'increase_expert_weight':
            # å¢åŠ ä¸“å®¶çŸ¥è¯†ç‰¹å¾çš„æƒé‡ Increase weight of expert knowledge features
            if self.current_strategy == 'S_auto_opt':
                self.current_strategy = 'S_auto_opt+expert'
            elif self.current_strategy == 'S_raw':
                self.current_strategy = 'S_expert'
            
        elif suggestion == 'try_multi_dimensional':
            # å°è¯•å¤šç»´åº¦è‡ªç¼–ç å™¨ Try multi-dimensional autoencoder
            if 'multi' not in self.current_strategy:
                self.current_strategy = 'S_auto_multi+expert'
        
        elif suggestion == 'simplify_features':
            # ç®€åŒ–ç‰¹å¾ Simplify features
            if 'multi' in self.current_strategy:
                self.current_strategy = 'S_auto_opt+expert'
            elif 'auto_opt+expert' in self.current_strategy:
                self.current_strategy = 'S_expert'
            
        elif suggestion == 'try_raw_features':
            # å°è¯•åŸå§‹ç‰¹å¾ Try raw features
            self.current_strategy = 'S_raw'
            
        else:
            # é»˜è®¤ç­–ç•¥åºåˆ— Default strategy sequence
            strategy_sequence = ['S_auto_opt+expert', 'S_auto_multi+expert', 'S_expert', 'S_auto_opt', 'S_raw']
            current_idx = strategy_sequence.index(self.current_strategy) if self.current_strategy in strategy_sequence else 0
            next_idx = (current_idx + 1) % len(strategy_sequence)
            self.current_strategy = strategy_sequence[next_idx]
        
        self.adjustment_count += 1
        
        print(f"ğŸ”„ ç­–ç•¥è°ƒæ•´: {old_strategy} -> {self.current_strategy}")
        print(f"ğŸ”„ Strategy adjustment: {old_strategy} -> {self.current_strategy}")
        print(f"ğŸ“Š è°ƒæ•´æ¬¡æ•°: {self.adjustment_count}")
        print(f"ğŸ“Š Adjustment count: {self.adjustment_count}")
    
    def adjust_for_high_errors(self, high_error_categories: List[str], forecasting_errors: Dict[str, float]):
        """
        é’ˆå¯¹é«˜è¯¯å·®ç±»åˆ«è°ƒæ•´å‚æ•°
        Adjust parameters for high error categories
        
        å‚æ•° Args:
            high_error_categories (List[str]): é«˜è¯¯å·®ç±»åˆ«åˆ—è¡¨ List of high error categories
            forecasting_errors (Dict[str, float]): é¢„æµ‹è¯¯å·®å­—å…¸ Forecasting errors dictionary
        """
        print(f"\nğŸ¯ é’ˆå¯¹é«˜è¯¯å·®ç±»åˆ«è¿›è¡Œå‚æ•°è°ƒæ•´")
        print(f"ğŸ¯ Adjusting parameters for high error categories")
        
        # åŠ¨æ€è°ƒæ•´è‡ªç¼–ç å™¨ç»´åº¦ Dynamically adjust autoencoder dimensions
        if len(high_error_categories) > len(self.multi_dims) // 2:
            # å¦‚æœå¤§éƒ¨åˆ†ç±»åˆ«éƒ½æœ‰é«˜è¯¯å·®ï¼Œå¢åŠ ç¼–ç ç»´åº¦
            self.encoding_dim = min(20, self.encoding_dim + 2)
            print(f"ğŸ”§ å¢åŠ ç¼–ç ç»´åº¦è‡³: {self.encoding_dim}")
            print(f"ğŸ”§ Increased encoding dimension to: {self.encoding_dim}")
            
            # é‡æ–°æ„å»ºè‡ªç¼–ç å™¨ Rebuild autoencoder
            dim_key = f"dim_{self.encoding_dim}"
            if dim_key in self.autoencoders:
                del self.autoencoders[dim_key]
                del self.encoders[dim_key]
        
        # è€ƒè™‘é‡æ–°æ¿€æ´»åŸå§‹éœ€æ±‚ç‰¹å¾ Consider reactivating raw demand features
        avg_error = np.mean(list(forecasting_errors.values()))
        if avg_error > 10.0:  # å¦‚æœå¹³å‡è¯¯å·®å¾ˆé«˜
            print("ğŸ”„ è¯¯å·®è¿‡é«˜ï¼Œè€ƒè™‘é‡æ–°æ¿€æ´»åŸå§‹éœ€æ±‚ç‰¹å¾")
            print("ğŸ”„ Error too high, considering reactivation of raw demand features")
            self.current_strategy = 'S_raw'
    
    def get_strategy_performance_summary(self) -> Dict[str, any]:
        """
        è·å–ç­–ç•¥æ€§èƒ½æ‘˜è¦
        Get strategy performance summary
        
        è¿”å› Returns:
            Dict[str, any]: ç­–ç•¥æ€§èƒ½æ‘˜è¦ Strategy performance summary
        """
        summary = {
            'current_strategy': self.current_strategy,
            'total_adjustments': self.adjustment_count,
            'strategy_history': self.strategy_history[-10:],  # æœ€è¿‘10æ¬¡è®°å½•
            'feedback_count': len(self.feedback_signals),
            'encoding_dim': self.encoding_dim,
            'multi_dims': self.multi_dims,
            'available_models': list(self.autoencoders.keys())
        }
        
        return summary
    
    def save_agent_state(self, filepath: str):
        """
        ä¿å­˜ä»£ç†çŠ¶æ€
        Save agent state
        
        å‚æ•° Args:
            filepath (str): ä¿å­˜æ–‡ä»¶è·¯å¾„ Save file path
        """
        state = {
            'current_strategy': self.current_strategy,
            'encoding_dim': self.encoding_dim,
            'autoencoder_epochs': self.autoencoder_epochs,
            'batch_size': self.batch_size,
            'multi_dims': self.multi_dims,
            'feedback_threshold': self.feedback_threshold,
            'strategy_history': self.strategy_history,
            'feedback_signals': self.feedback_signals,
            'adjustment_count': self.adjustment_count,
            'performance_history': self.performance_history
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ä»£ç†çŠ¶æ€å·²ä¿å­˜è‡³: {filepath}")
        print(f"ğŸ’¾ Agent state saved to: {filepath}")
    
    def load_agent_state(self, filepath: str):
        """
        åŠ è½½ä»£ç†çŠ¶æ€
        Load agent state
        
        å‚æ•° Args:
            filepath (str): åŠ è½½æ–‡ä»¶è·¯å¾„ Load file path
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            state = json.load(f)
        
        self.current_strategy = state.get('current_strategy', 'S_auto_opt+expert')
        self.encoding_dim = state.get('encoding_dim', 12)
        self.autoencoder_epochs = state.get('autoencoder_epochs', 50)
        self.batch_size = state.get('batch_size', 16)
        self.multi_dims = state.get('multi_dims', [8, 12, 16])
        self.feedback_threshold = state.get('feedback_threshold', 0.9)
        self.strategy_history = state.get('strategy_history', [])
        self.feedback_signals = state.get('feedback_signals', [])
        self.adjustment_count = state.get('adjustment_count', 0)
        self.performance_history = state.get('performance_history', {})
        
        print(f"ğŸ“ ä»£ç†çŠ¶æ€å·²åŠ è½½: {filepath}")
        print(f"ğŸ“ Agent state loaded from: {filepath}")
        print(f"ğŸ¯ å½“å‰ç­–ç•¥: {self.current_strategy}")
        print(f"ğŸ¯ Current strategy: {self.current_strategy}")


def demo_feature_extraction_agent():
    """
    æ¼”ç¤ºç‰¹å¾æå–ä»£ç†çš„åŠŸèƒ½
    Demonstrate the functionality of Feature Extraction Agent
    """
    print("ğŸš€ ç‰¹å¾æå–ä»£ç†æ¼”ç¤º Feature Extraction Agent Demo")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ® Create simulation data
    np.random.seed(42)
    n_series = 100
    n_periods = 84
    
    data = pd.DataFrame()
    for i in range(n_series):
        # ç”Ÿæˆé—´æ­‡æ€§éœ€æ±‚æ•°æ® Generate intermittent demand data
        demand = np.random.poisson(1.5, n_periods)
        demand = np.where(np.random.random(n_periods) > 0.7, demand, 0)
        data[f'item_{i:03d}'] = demand
    
    print(f"ğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {data.shape}")
    print(f"ğŸ“Š Generated simulation data: {data.shape}")
    
    # åˆå§‹åŒ–ä»£ç† Initialize agent
    agent = FeatureExtractionAgent(
        encoding_dim=12,
        autoencoder_epochs=5,  # å‡å°‘è®­ç»ƒæ—¶é—´ç”¨äºæ¼”ç¤º
        multi_dims=[8, 12, 16]
    )
    
    # æµ‹è¯•æ‰€æœ‰ç­–ç•¥ Test all strategies
    for strategy in agent.strategies.keys():
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•ç­–ç•¥: {strategy}")
        print(f"ğŸ§ª Testing strategy: {strategy}")
        print(f"{'='*60}")
        
        features = agent.extract_features_by_strategy(data, strategy)
        print(f"ğŸ“ˆ æå–ç‰¹å¾å½¢çŠ¶: {features.shape}")
        print(f"ğŸ“ˆ Extracted features shape: {features.shape}")
    
    # æ¨¡æ‹Ÿåé¦ˆè°ƒæ•´ Simulate feedback adjustment
    print(f"\n{'='*60}")
    print("ğŸ”„ æ¨¡æ‹Ÿåé¦ˆè°ƒæ•´ Simulating feedback adjustment")
    print(f"{'='*60}")
    
    # æ¨¡æ‹Ÿä½èšç±»åˆ†æ•°çš„åé¦ˆ Simulate low clustering score feedback
    feedback = {
        'clustering_score': 0.75,  # ä½äºé˜ˆå€¼0.9
        'forecasting_errors': {'category_1': 7.5, 'category_2': 3.2},
        'suggestion': 'increase_expert_weight'
    }
    
    agent.receive_feedback(feedback)
    
    # ä½¿ç”¨è°ƒæ•´åçš„ç­–ç•¥æå–ç‰¹å¾ Extract features with adjusted strategy
    adjusted_features = agent.extract_features_by_strategy(data)
    print(f"ğŸ“Š è°ƒæ•´åç‰¹å¾å½¢çŠ¶: {adjusted_features.shape}")
    print(f"ğŸ“Š Adjusted features shape: {adjusted_features.shape}")
    
    # æ˜¾ç¤ºæ€§èƒ½æ‘˜è¦ Show performance summary
    summary = agent.get_strategy_performance_summary()
    print(f"\nğŸ“‹ æ€§èƒ½æ‘˜è¦ Performance Summary:")
    print(f"   å½“å‰ç­–ç•¥ Current strategy: {summary['current_strategy']}")
    print(f"   è°ƒæ•´æ¬¡æ•° Total adjustments: {summary['total_adjustments']}")
    print(f"   åé¦ˆæ¬¡æ•° Feedback count: {summary['feedback_count']}")
    
    # ä¿å­˜ä»£ç†çŠ¶æ€ Save agent state
    agent.save_agent_state("feature_extraction_agent_demo_state.json")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆ Demo completed!")


if __name__ == "__main__":
    demo_feature_extraction_agent() 